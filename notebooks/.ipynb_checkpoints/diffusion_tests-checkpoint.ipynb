{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70e06b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from os import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import k3d\n",
    "from tqdm.notebook import tqdm\n",
    "from models.diffusion import *\n",
    "from datasets.shapenet import *\n",
    "from torch.utils.data import DataLoader\n",
    "from models.latent_cond.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123e3e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3030104790>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "torch.manual_seed(34533)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b87341a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffusionModel(\n",
       "  (extractor): NoisePredictor(\n",
       "    (encoder): PointNetEncoder(\n",
       "      (conv1): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc1_m): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc2_m): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (fc3_m): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (fc_bn1_m): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc_bn2_m): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc1_v): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc2_v): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (fc3_v): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (fc_bn1_v): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc_bn2_v): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (an1): LatentInjector(\n",
       "      (proj): Sequential(\n",
       "        (0): Linear(in_features=515, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Linear(in_features=512, out_features=3, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (down1): PointNetMSG(\n",
       "      (mlps): ModuleList(\n",
       "        (0): MLP(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv1d(6, 16, kernel_size=(1,), stride=(1,))\n",
       "            (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.02)\n",
       "            (3): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
       "            (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): LeakyReLU(negative_slope=0.02)\n",
       "            (6): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "            (7): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): MLP(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv1d(6, 32, kernel_size=(1,), stride=(1,))\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.02)\n",
       "            (3): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "            (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): LeakyReLU(negative_slope=0.02)\n",
       "            (6): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "            (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (attention): ModuleList(\n",
       "        (0): AttentionMix(\n",
       "          (q): Conv1d(6, 12, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (v): Conv2d(6, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (k): Conv2d(6, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (out): Conv1d(12, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "        (1): AttentionMix(\n",
       "          (q): Conv1d(6, 12, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (v): Conv2d(6, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (k): Conv2d(6, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (out): Conv1d(12, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (an2): LatentInjector(\n",
       "      (proj): Sequential(\n",
       "        (0): Linear(in_features=515, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Linear(in_features=512, out_features=96, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (down2): PointNetMSG(\n",
       "      (mlps): ModuleList(\n",
       "        (0): MLP(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv1d(99, 64, kernel_size=(1,), stride=(1,))\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.02)\n",
       "            (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): LeakyReLU(negative_slope=0.02)\n",
       "            (6): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "            (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): MLP(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv1d(99, 64, kernel_size=(1,), stride=(1,))\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.02)\n",
       "            (3): Conv1d(64, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): LeakyReLU(negative_slope=0.02)\n",
       "            (6): Conv1d(96, 128, kernel_size=(1,), stride=(1,))\n",
       "            (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (attention): ModuleList(\n",
       "        (0): AttentionMix(\n",
       "          (q): Conv1d(99, 198, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (v): Conv2d(99, 198, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (k): Conv2d(99, 198, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (out): Conv1d(198, 99, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "        (1): AttentionMix(\n",
       "          (q): Conv1d(99, 198, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (v): Conv2d(99, 198, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (k): Conv2d(99, 198, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (out): Conv1d(198, 99, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (an3): LatentInjector(\n",
       "      (proj): Sequential(\n",
       "        (0): Linear(in_features=515, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (down3): PointNetMSG(\n",
       "      (mlps): ModuleList(\n",
       "        (0): MLP(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv1d(259, 128, kernel_size=(1,), stride=(1,))\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.02)\n",
       "            (3): Conv1d(128, 196, kernel_size=(1,), stride=(1,))\n",
       "            (4): BatchNorm1d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): LeakyReLU(negative_slope=0.02)\n",
       "            (6): Conv1d(196, 256, kernel_size=(1,), stride=(1,))\n",
       "            (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): MLP(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv1d(259, 128, kernel_size=(1,), stride=(1,))\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): LeakyReLU(negative_slope=0.02)\n",
       "            (3): Conv1d(128, 196, kernel_size=(1,), stride=(1,))\n",
       "            (4): BatchNorm1d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): LeakyReLU(negative_slope=0.02)\n",
       "            (6): Conv1d(196, 256, kernel_size=(1,), stride=(1,))\n",
       "            (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (attention): ModuleList(\n",
       "        (0): AttentionMix(\n",
       "          (q): Conv1d(259, 518, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (v): Conv2d(259, 518, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (k): Conv2d(259, 518, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (out): Conv1d(518, 259, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "        (1): AttentionMix(\n",
       "          (q): Conv1d(259, 518, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (v): Conv2d(259, 518, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (k): Conv2d(259, 518, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (out): Conv1d(518, 259, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (attn1): Attention1d(\n",
       "      (q): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (v): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (k): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (an4): LatentInjector(\n",
       "      (proj): Sequential(\n",
       "        (0): Linear(in_features=515, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (up1): FeaturePropagation(\n",
       "      (attention): Attention1d(\n",
       "        (q): Conv1d(259, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v): Conv1d(515, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k): Conv1d(515, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 256, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.02)\n",
       "          (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (an5): LatentInjector(\n",
       "      (proj): Sequential(\n",
       "        (0): Linear(in_features=515, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (up2): FeaturePropagation(\n",
       "      (attention): Attention1d(\n",
       "        (q): Conv1d(99, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v): Conv1d(259, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k): Conv1d(259, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (out): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(352, 256, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.02)\n",
       "          (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.02)\n",
       "          (6): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (an6): LatentInjector(\n",
       "      (proj): Sequential(\n",
       "        (0): Linear(in_features=515, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (up3): FeaturePropagation(\n",
       "      (attention): Attention1d(\n",
       "        (q): Conv1d(6, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v): Conv1d(131, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k): Conv1d(131, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (out): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(131, 128, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.02)\n",
       "          (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.02)\n",
       "          (6): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "          (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (predictor): Sequential(\n",
       "      (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (3): Conv1d(512, 3, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "model = DiffusionModel(NoisePredictor(3, residual=True),\n",
    "                       1000,\n",
    "                       time_embedding_dim=3).to(device)\n",
    "state = torch.load('model_299.pt')\n",
    "model.load_state_dict(state['model'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa72b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset('../../datasets', dataset_name='shapenetpart', class_choice='airplane', split='val', segmentation=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb158f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_loader))\n",
    "x = batch[0].transpose(2, 1).to(device)\n",
    "labels = batch[2]\n",
    "timesteps = [50, 100, 300, 500, 700, 800]\n",
    "features, coords = model.get_features(x, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d82f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(x, y, y_features):\n",
    "    dists = (\n",
    "        y.pow(2).sum(dim=1, keepdim=True) -\n",
    "        2 * torch.bmm(x.transpose(2, 1), y)\n",
    "        + x.pow(2).sum(dim=1).unsqueeze(2)\n",
    "    )\n",
    "    weights, idx = torch.topk(dists.pow(2), 3, largest=False, sorted=False, dim=2)\n",
    "    weights = 1 / (weights + 1e-8)\n",
    "    weights /= weights.sum(dim=2, keepdim=True)\n",
    "\n",
    "            # idx: bs x n x 3\n",
    "    bs, _, n_points = x.shape\n",
    "    channels = y_features.size(1)\n",
    "    interpolated = torch.gather(y_features, 2, idx.view(bs, 1, -1).expand(-1, channels, -1))\n",
    "    interpolated = interpolated.view(bs, channels, n_points, 3) * weights.unsqueeze(1)\n",
    "    \n",
    "    return interpolated.sum(dim=3)\n",
    "\n",
    "def combine_features(x, features, centroids):\n",
    "    features_list = [features[0]]\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        interpolated = interpolate(x, centroids[i-1], features[i])\n",
    "\n",
    "        features_list.append(interpolated)\n",
    "        \n",
    "    return torch.cat(features_list, dim=1)\n",
    "\n",
    "def center(points):\n",
    "    max_p = points.max(dim=2)[0]\n",
    "    min_p = points.min(dim=2)[0]\n",
    "    shift = (max_p + min_p) / 2\n",
    "    \n",
    "    points = points - shift.unsqueeze(2)\n",
    "    y = points[:, 1, :].clone()\n",
    "    points[:, 1, :] = points[:, 2, :].clone()\n",
    "    points[:, 2, :] = y\n",
    "    \n",
    "    return points.cpu().transpose(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973d61c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_features = []\n",
    "\n",
    "for t in timesteps:\n",
    "    agg_features.append(combine_features(x, features[t], coords[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56fb34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b7ba99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kmeans(features, n_clusters):\n",
    "    batch_size, dim, n_pts = features.shape\n",
    "    train_dataset = features.transpose(2, 1).reshape(-1, dim).cpu()\n",
    "    labels = KMeans(n_clusters=n_clusters).fit_predict(train_dataset).reshape(batch_size, n_pts)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8873ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_100_3 = train_kmeans(agg_features[1], 3)\n",
    "labels_300_3 = train_kmeans(agg_features[2], 3)\n",
    "labels_500_3 = train_kmeans(agg_features[2], 3)\n",
    "\n",
    "labels_100_5 = train_kmeans(agg_features[1], 5)\n",
    "labels_300_5 = train_kmeans(agg_features[2], 5)\n",
    "labels_500_5 = train_kmeans(agg_features[2], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2ad1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_centered = center(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09977706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bead421ca25486abce6bead9112065f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k3d.points(x_centered[0], point_size=0.05, attribute=labels_500_5[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeeef91",
   "metadata": {},
   "source": [
    "### FewShort Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "146af3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_channels, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(num_features=32),\n",
    "            nn.Linear(32, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def prepare_train_dataset(dataset, n_samples, timesteps):\n",
    "    idx = torch.randperm(len(dataset))[:n_samples].tolist()\n",
    "    points = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in idx:\n",
    "        sample = dataset[i]\n",
    "        points.append(sample[0].t().unsqueeze(0))\n",
    "        labels.append(sample[2].unsqueeze(0))\n",
    "        \n",
    "    points = torch.cat(points, dim=0).to(device)\n",
    "    labels = torch.cat(labels, dim=0).to(device)\n",
    "    \n",
    "    features, coords = model.get_features(points, timesteps)\n",
    "    agg_features = {}\n",
    "    \n",
    "    for t in timesteps:\n",
    "        agg_features[t] = combine_features(points, features[t], coords[t])\n",
    "        agg_features[t] = agg_features[t].transpose(2, 1).flatten(start_dim=0, end_dim=1)\n",
    "    \n",
    "    data = {\n",
    "        'features': agg_features,\n",
    "        'labels': labels.flatten(start_dim=0, end_dim=1)\n",
    "    }\n",
    "    torch.save(data, f'dataset_{n_samples}')\n",
    "    \n",
    "    return data\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, data, timestep, batch_size=128 * 2048):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    running_loss = 0\n",
    "    model.eval()\n",
    "    \n",
    "    batches = data['features'][timestep].reshape(-1, 2048, 1152)\n",
    "    labels = data['labels'].reshape(-1, 2048)\n",
    "    intersections = {0: 0, 1: 0, 2: 0, 3: 0}\n",
    "    unions = {0: 0, 1: 0, 2: 0, 3: 0}\n",
    "    \n",
    "    all_preds = []\n",
    "    \n",
    "    for x, l in tqdm(zip(batches, labels)):\n",
    "        logits = model(x)\n",
    "        running_loss += loss(logits, l)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.append(preds)\n",
    "        for i in range(4):\n",
    "            intersections[i] += ((preds == i) & (l == i)).sum()\n",
    "            unions[i] += ((preds == i) | (l == i)).sum()\n",
    "            \n",
    "    ious = []\n",
    "    for i in range(4):\n",
    "        iou = intersections[i] / (1e-8 + unions[i])\n",
    "        ious.append(iou)\n",
    "    \n",
    "    return torch.tensor(ious).mean(), ious, torch.stack(all_preds, dim=0), running_loss.item() / len(batches)\n",
    "\n",
    "def train_model(model, data, timestep, epoch_num, batch_size=128):\n",
    "    features = data['features'][timestep]\n",
    "    labels = data['labels']\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for epoch in range(epoch_num):\n",
    "        perm = torch.randperm(len(features))\n",
    "        batches = features[perm].split(batch_size, dim=0)\n",
    "        l_batches = labels[perm].split(batch_size, dim=0)\n",
    "        bar = tqdm(enumerate(zip(batches, l_batches)), total=len(batches))\n",
    "        \n",
    "        for i, (x, l) in bar:\n",
    "            if x.shape[0] == 1:\n",
    "                continue\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss_t = loss(logits, l)\n",
    "            loss_t.backward()\n",
    "            running_loss += loss_t.item() \n",
    "            optimizer.step()\n",
    "            \n",
    "            bar.set_postfix({\n",
    "                'Epoch': epoch,\n",
    "                'Loss': running_loss / (i+1)\n",
    "            })\n",
    "            \n",
    "        running_loss = 0\n",
    "            \n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808adde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset('../../datasets', dataset_name='shapenetpart',\n",
    "                        class_choice='airplane', split='train', segmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fd35fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.07it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "data_3samples = prepare_train_dataset(train_dataset, 3, [100, 300, 500])\n",
    "data_10samples = prepare_train_dataset(train_dataset, 10, [100, 300, 500])\n",
    "data_20samples = prepare_train_dataset(train_dataset, 20, [100, 300, 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a811716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 140.01it/s, Epoch=0, Loss=0.63] \n",
      "100%|██████████| 48/48 [00:00<00:00, 146.53it/s, Epoch=1, Loss=0.389]\n",
      "100%|██████████| 48/48 [00:00<00:00, 140.21it/s, Epoch=2, Loss=0.319]\n",
      "100%|██████████| 48/48 [00:00<00:00, 136.86it/s, Epoch=3, Loss=0.275]\n",
      "100%|██████████| 48/48 [00:00<00:00, 139.20it/s, Epoch=4, Loss=0.249]\n",
      "100%|██████████| 48/48 [00:00<00:00, 160.02it/s, Epoch=5, Loss=0.233]\n",
      "100%|██████████| 48/48 [00:00<00:00, 148.03it/s, Epoch=6, Loss=0.226]\n",
      "100%|██████████| 48/48 [00:00<00:00, 205.62it/s, Epoch=7, Loss=0.217]\n",
      "100%|██████████| 48/48 [00:00<00:00, 161.00it/s, Epoch=8, Loss=0.205]\n",
      "100%|██████████| 48/48 [00:00<00:00, 160.61it/s, Epoch=9, Loss=0.186]\n",
      "100%|██████████| 48/48 [00:00<00:00, 147.80it/s, Epoch=10, Loss=0.183]\n",
      "100%|██████████| 48/48 [00:00<00:00, 143.57it/s, Epoch=11, Loss=0.181]\n",
      "100%|██████████| 48/48 [00:00<00:00, 138.17it/s, Epoch=12, Loss=0.171]\n",
      "100%|██████████| 48/48 [00:00<00:00, 173.32it/s, Epoch=13, Loss=0.17] \n",
      "100%|██████████| 48/48 [00:00<00:00, 139.06it/s, Epoch=14, Loss=0.165]\n",
      "100%|██████████| 48/48 [00:00<00:00, 149.46it/s, Epoch=15, Loss=0.161]\n",
      "100%|██████████| 48/48 [00:00<00:00, 150.21it/s, Epoch=16, Loss=0.155]\n",
      "100%|██████████| 48/48 [00:00<00:00, 179.74it/s, Epoch=17, Loss=0.139]\n",
      "100%|██████████| 48/48 [00:00<00:00, 146.92it/s, Epoch=18, Loss=0.148]\n",
      "100%|██████████| 48/48 [00:00<00:00, 144.11it/s, Epoch=19, Loss=0.149]\n",
      "100%|██████████| 48/48 [00:00<00:00, 143.70it/s, Epoch=20, Loss=0.141]\n",
      "100%|██████████| 48/48 [00:00<00:00, 155.59it/s, Epoch=21, Loss=0.138]\n",
      "100%|██████████| 48/48 [00:00<00:00, 145.59it/s, Epoch=22, Loss=0.137]\n",
      "100%|██████████| 48/48 [00:00<00:00, 164.88it/s, Epoch=23, Loss=0.13] \n",
      "100%|██████████| 48/48 [00:00<00:00, 158.09it/s, Epoch=24, Loss=0.135]\n",
      "100%|██████████| 48/48 [00:00<00:00, 136.08it/s, Epoch=25, Loss=0.126]\n",
      "100%|██████████| 48/48 [00:00<00:00, 146.24it/s, Epoch=26, Loss=0.134]\n",
      "100%|██████████| 48/48 [00:00<00:00, 156.97it/s, Epoch=27, Loss=0.124]\n",
      "100%|██████████| 48/48 [00:00<00:00, 147.19it/s, Epoch=28, Loss=0.118]\n",
      "100%|██████████| 48/48 [00:00<00:00, 165.24it/s, Epoch=29, Loss=0.124]\n",
      "100%|██████████| 48/48 [00:00<00:00, 143.24it/s, Epoch=30, Loss=0.12] \n",
      "100%|██████████| 48/48 [00:00<00:00, 132.43it/s, Epoch=31, Loss=0.114]\n",
      "100%|██████████| 48/48 [00:00<00:00, 144.02it/s, Epoch=32, Loss=0.122]\n",
      "100%|██████████| 48/48 [00:00<00:00, 148.98it/s, Epoch=33, Loss=0.118]\n",
      "100%|██████████| 48/48 [00:00<00:00, 162.18it/s, Epoch=34, Loss=0.112]\n",
      "100%|██████████| 48/48 [00:00<00:00, 165.59it/s, Epoch=35, Loss=0.109]\n",
      "100%|██████████| 48/48 [00:00<00:00, 148.13it/s, Epoch=36, Loss=0.107]\n",
      "100%|██████████| 48/48 [00:00<00:00, 132.93it/s, Epoch=37, Loss=0.102]\n",
      "100%|██████████| 48/48 [00:00<00:00, 156.08it/s, Epoch=38, Loss=0.103]\n",
      "100%|██████████| 48/48 [00:00<00:00, 140.07it/s, Epoch=39, Loss=0.0988]\n",
      "100%|██████████| 48/48 [00:00<00:00, 154.56it/s, Epoch=40, Loss=0.103] \n",
      "100%|██████████| 48/48 [00:00<00:00, 141.95it/s, Epoch=41, Loss=0.1]   \n",
      "100%|██████████| 48/48 [00:00<00:00, 159.95it/s, Epoch=42, Loss=0.0992]\n",
      "100%|██████████| 48/48 [00:00<00:00, 151.41it/s, Epoch=43, Loss=0.105] \n",
      "100%|██████████| 48/48 [00:00<00:00, 229.15it/s, Epoch=44, Loss=0.0898]\n",
      "100%|██████████| 48/48 [00:00<00:00, 154.47it/s, Epoch=45, Loss=0.0924]\n",
      "100%|██████████| 48/48 [00:00<00:00, 134.66it/s, Epoch=46, Loss=0.0967]\n",
      "100%|██████████| 48/48 [00:00<00:00, 138.53it/s, Epoch=47, Loss=0.0895]\n",
      "100%|██████████| 48/48 [00:00<00:00, 152.15it/s, Epoch=48, Loss=0.0917]\n",
      "100%|██████████| 48/48 [00:00<00:00, 169.30it/s, Epoch=49, Loss=0.09]  \n",
      "100%|██████████| 48/48 [00:00<00:00, 142.82it/s, Epoch=50, Loss=0.0851]\n",
      "100%|██████████| 48/48 [00:00<00:00, 141.24it/s, Epoch=51, Loss=0.0877]\n",
      "100%|██████████| 48/48 [00:00<00:00, 142.47it/s, Epoch=52, Loss=0.0851]\n",
      "100%|██████████| 48/48 [00:00<00:00, 133.16it/s, Epoch=53, Loss=0.0824]\n",
      "100%|██████████| 48/48 [00:00<00:00, 160.20it/s, Epoch=54, Loss=0.0852]\n",
      "100%|██████████| 48/48 [00:00<00:00, 157.67it/s, Epoch=55, Loss=0.087] \n",
      "100%|██████████| 48/48 [00:00<00:00, 146.40it/s, Epoch=56, Loss=0.0785]\n",
      "100%|██████████| 48/48 [00:00<00:00, 142.34it/s, Epoch=57, Loss=0.0859]\n",
      "100%|██████████| 48/48 [00:00<00:00, 164.68it/s, Epoch=58, Loss=0.0871]\n",
      "100%|██████████| 48/48 [00:00<00:00, 182.80it/s, Epoch=59, Loss=0.0772]\n",
      "100%|██████████| 48/48 [00:00<00:00, 131.44it/s, Epoch=60, Loss=0.0748]\n",
      "100%|██████████| 48/48 [00:00<00:00, 147.96it/s, Epoch=61, Loss=0.0745]\n",
      "100%|██████████| 48/48 [00:00<00:00, 162.73it/s, Epoch=62, Loss=0.071] \n",
      "100%|██████████| 48/48 [00:00<00:00, 164.42it/s, Epoch=63, Loss=0.0742]\n",
      "100%|██████████| 48/48 [00:00<00:00, 152.57it/s, Epoch=64, Loss=0.0702]\n",
      "100%|██████████| 48/48 [00:00<00:00, 130.74it/s, Epoch=65, Loss=0.0776]\n",
      "100%|██████████| 48/48 [00:00<00:00, 139.04it/s, Epoch=66, Loss=0.0801]\n",
      "100%|██████████| 48/48 [00:00<00:00, 149.35it/s, Epoch=67, Loss=0.0749]\n",
      "100%|██████████| 48/48 [00:00<00:00, 143.43it/s, Epoch=68, Loss=0.0733]\n",
      "100%|██████████| 48/48 [00:00<00:00, 140.13it/s, Epoch=69, Loss=0.0693]\n",
      "100%|██████████| 48/48 [00:00<00:00, 143.96it/s, Epoch=70, Loss=0.0664]\n",
      "100%|██████████| 48/48 [00:00<00:00, 164.84it/s, Epoch=71, Loss=0.0671]\n",
      "100%|██████████| 48/48 [00:00<00:00, 155.75it/s, Epoch=72, Loss=0.0674]\n",
      "100%|██████████| 48/48 [00:00<00:00, 147.98it/s, Epoch=73, Loss=0.0692]\n",
      "100%|██████████| 48/48 [00:00<00:00, 152.96it/s, Epoch=74, Loss=0.0668]\n",
      "100%|██████████| 48/48 [00:00<00:00, 134.42it/s, Epoch=75, Loss=0.0676]\n",
      "100%|██████████| 48/48 [00:00<00:00, 147.03it/s, Epoch=76, Loss=0.0659]\n",
      "100%|██████████| 48/48 [00:00<00:00, 146.79it/s, Epoch=77, Loss=0.0641]\n",
      "100%|██████████| 48/48 [00:00<00:00, 190.55it/s, Epoch=78, Loss=0.0673]\n",
      "100%|██████████| 48/48 [00:00<00:00, 137.06it/s, Epoch=79, Loss=0.0656]\n",
      "100%|██████████| 48/48 [00:00<00:00, 149.17it/s, Epoch=80, Loss=0.0631]\n",
      "100%|██████████| 48/48 [00:00<00:00, 153.32it/s, Epoch=81, Loss=0.0633]\n",
      "100%|██████████| 48/48 [00:00<00:00, 147.69it/s, Epoch=82, Loss=0.0649]\n",
      "100%|██████████| 48/48 [00:00<00:00, 156.86it/s, Epoch=83, Loss=0.0628]\n",
      "100%|██████████| 48/48 [00:00<00:00, 156.60it/s, Epoch=84, Loss=0.0652]\n",
      "100%|██████████| 48/48 [00:00<00:00, 132.26it/s, Epoch=85, Loss=0.0567]\n",
      "100%|██████████| 48/48 [00:00<00:00, 148.37it/s, Epoch=86, Loss=0.064] \n",
      "100%|██████████| 48/48 [00:00<00:00, 151.75it/s, Epoch=87, Loss=0.0599]\n",
      "100%|██████████| 48/48 [00:00<00:00, 147.99it/s, Epoch=88, Loss=0.0634]\n",
      "100%|██████████| 48/48 [00:00<00:00, 168.81it/s, Epoch=89, Loss=0.059] \n",
      "100%|██████████| 48/48 [00:00<00:00, 175.27it/s, Epoch=90, Loss=0.0548]\n",
      "100%|██████████| 48/48 [00:00<00:00, 189.48it/s, Epoch=91, Loss=0.0597]\n",
      "100%|██████████| 48/48 [00:00<00:00, 176.21it/s, Epoch=92, Loss=0.056] \n",
      "100%|██████████| 48/48 [00:00<00:00, 169.80it/s, Epoch=93, Loss=0.0521]\n",
      "100%|██████████| 48/48 [00:00<00:00, 136.15it/s, Epoch=94, Loss=0.055] \n",
      "100%|██████████| 48/48 [00:00<00:00, 142.75it/s, Epoch=95, Loss=0.0563]\n",
      "100%|██████████| 48/48 [00:00<00:00, 145.32it/s, Epoch=96, Loss=0.0578]\n",
      "100%|██████████| 48/48 [00:00<00:00, 153.89it/s, Epoch=97, Loss=0.0532]\n",
      "100%|██████████| 48/48 [00:00<00:00, 153.88it/s, Epoch=98, Loss=0.0553]\n",
      "100%|██████████| 48/48 [00:00<00:00, 152.89it/s, Epoch=99, Loss=0.0565]\n",
      "100%|██████████| 48/48 [00:00<00:00, 149.43it/s, Epoch=0, Loss=0.665]\n",
      "100%|██████████| 48/48 [00:00<00:00, 139.97it/s, Epoch=1, Loss=0.43] \n",
      "100%|██████████| 48/48 [00:00<00:00, 181.53it/s, Epoch=2, Loss=0.369]\n",
      "100%|██████████| 48/48 [00:00<00:00, 151.02it/s, Epoch=3, Loss=0.327]\n",
      "100%|██████████| 48/48 [00:00<00:00, 162.93it/s, Epoch=4, Loss=0.305]\n",
      "100%|██████████| 48/48 [00:00<00:00, 160.34it/s, Epoch=5, Loss=0.292]\n",
      "100%|██████████| 48/48 [00:00<00:00, 133.03it/s, Epoch=6, Loss=0.272]\n",
      "100%|██████████| 48/48 [00:00<00:00, 135.73it/s, Epoch=7, Loss=0.257]\n",
      "100%|██████████| 48/48 [00:00<00:00, 152.34it/s, Epoch=8, Loss=0.258]\n",
      "100%|██████████| 48/48 [00:00<00:00, 145.41it/s, Epoch=9, Loss=0.241]\n",
      "100%|██████████| 48/48 [00:00<00:00, 140.28it/s, Epoch=10, Loss=0.238]\n",
      "100%|██████████| 48/48 [00:00<00:00, 147.56it/s, Epoch=11, Loss=0.228]\n",
      "100%|██████████| 48/48 [00:00<00:00, 139.27it/s, Epoch=12, Loss=0.223]\n",
      "100%|██████████| 48/48 [00:00<00:00, 143.07it/s, Epoch=13, Loss=0.215]\n",
      "100%|██████████| 48/48 [00:00<00:00, 138.22it/s, Epoch=14, Loss=0.218]\n",
      "100%|██████████| 48/48 [00:00<00:00, 146.16it/s, Epoch=15, Loss=0.213]\n",
      "100%|██████████| 48/48 [00:00<00:00, 145.68it/s, Epoch=16, Loss=0.207]\n",
      "100%|██████████| 48/48 [00:00<00:00, 140.85it/s, Epoch=17, Loss=0.201]\n",
      "100%|██████████| 48/48 [00:00<00:00, 150.58it/s, Epoch=18, Loss=0.198]\n",
      "100%|██████████| 48/48 [00:00<00:00, 159.99it/s, Epoch=19, Loss=0.192]\n",
      "100%|██████████| 48/48 [00:00<00:00, 143.50it/s, Epoch=20, Loss=0.189]\n",
      "100%|██████████| 48/48 [00:00<00:00, 145.94it/s, Epoch=21, Loss=0.188]\n",
      "100%|██████████| 48/48 [00:00<00:00, 142.45it/s, Epoch=22, Loss=0.178]\n",
      "100%|██████████| 48/48 [00:00<00:00, 143.30it/s, Epoch=23, Loss=0.181]\n",
      "100%|██████████| 48/48 [00:00<00:00, 173.24it/s, Epoch=24, Loss=0.177]\n",
      "100%|██████████| 48/48 [00:00<00:00, 163.27it/s, Epoch=25, Loss=0.174]\n",
      "100%|██████████| 48/48 [00:00<00:00, 141.50it/s, Epoch=26, Loss=0.172]\n",
      "100%|██████████| 48/48 [00:00<00:00, 138.96it/s, Epoch=27, Loss=0.17] \n",
      "100%|██████████| 48/48 [00:00<00:00, 166.11it/s, Epoch=28, Loss=0.162]\n",
      "100%|██████████| 48/48 [00:00<00:00, 157.27it/s, Epoch=29, Loss=0.163]\n",
      "100%|██████████| 48/48 [00:00<00:00, 151.54it/s, Epoch=30, Loss=0.154]\n",
      "100%|██████████| 48/48 [00:00<00:00, 138.50it/s, Epoch=31, Loss=0.151]\n",
      "100%|██████████| 48/48 [00:00<00:00, 202.55it/s, Epoch=32, Loss=0.157]\n",
      "100%|██████████| 48/48 [00:00<00:00, 145.08it/s, Epoch=33, Loss=0.153]\n",
      "100%|██████████| 48/48 [00:00<00:00, 131.64it/s, Epoch=34, Loss=0.15] \n",
      "100%|██████████| 48/48 [00:00<00:00, 164.07it/s, Epoch=35, Loss=0.152]\n",
      "100%|██████████| 48/48 [00:00<00:00, 202.70it/s, Epoch=36, Loss=0.145]\n",
      "100%|██████████| 48/48 [00:00<00:00, 144.55it/s, Epoch=37, Loss=0.139]\n",
      "100%|██████████| 48/48 [00:00<00:00, 203.95it/s, Epoch=38, Loss=0.143]\n",
      "100%|██████████| 48/48 [00:00<00:00, 178.58it/s, Epoch=39, Loss=0.14] \n",
      "100%|██████████| 48/48 [00:00<00:00, 160.51it/s, Epoch=40, Loss=0.129]\n",
      "100%|██████████| 48/48 [00:00<00:00, 130.32it/s, Epoch=41, Loss=0.135]\n",
      "100%|██████████| 48/48 [00:00<00:00, 151.76it/s, Epoch=42, Loss=0.132]\n",
      "100%|██████████| 48/48 [00:00<00:00, 153.40it/s, Epoch=43, Loss=0.126]\n",
      "100%|██████████| 48/48 [00:00<00:00, 138.01it/s, Epoch=44, Loss=0.13] \n",
      "100%|██████████| 48/48 [00:00<00:00, 175.17it/s, Epoch=45, Loss=0.132]\n",
      "100%|██████████| 48/48 [00:00<00:00, 133.61it/s, Epoch=46, Loss=0.123]\n",
      "100%|██████████| 48/48 [00:00<00:00, 147.73it/s, Epoch=47, Loss=0.124]\n",
      "100%|██████████| 48/48 [00:00<00:00, 149.15it/s, Epoch=48, Loss=0.123]\n",
      "100%|██████████| 48/48 [00:00<00:00, 142.65it/s, Epoch=49, Loss=0.12] \n",
      "100%|██████████| 48/48 [00:00<00:00, 152.85it/s, Epoch=50, Loss=0.113]\n",
      "100%|██████████| 48/48 [00:00<00:00, 158.77it/s, Epoch=51, Loss=0.122]\n",
      "100%|██████████| 48/48 [00:00<00:00, 136.25it/s, Epoch=52, Loss=0.119]\n",
      "100%|██████████| 48/48 [00:00<00:00, 157.67it/s, Epoch=53, Loss=0.109] \n",
      "100%|██████████| 48/48 [00:00<00:00, 155.99it/s, Epoch=54, Loss=0.106]\n",
      "100%|██████████| 48/48 [00:00<00:00, 136.26it/s, Epoch=55, Loss=0.113] \n",
      "100%|██████████| 48/48 [00:00<00:00, 130.29it/s, Epoch=56, Loss=0.113]\n",
      "100%|██████████| 48/48 [00:00<00:00, 142.58it/s, Epoch=57, Loss=0.112]\n",
      "100%|██████████| 48/48 [00:00<00:00, 158.48it/s, Epoch=58, Loss=0.114]\n",
      "100%|██████████| 48/48 [00:00<00:00, 147.13it/s, Epoch=59, Loss=0.114]\n",
      "100%|██████████| 48/48 [00:00<00:00, 159.88it/s, Epoch=60, Loss=0.106]\n",
      "100%|██████████| 48/48 [00:00<00:00, 148.90it/s, Epoch=61, Loss=0.0993]\n",
      "100%|██████████| 48/48 [00:00<00:00, 167.52it/s, Epoch=62, Loss=0.103]\n",
      "100%|██████████| 48/48 [00:00<00:00, 151.72it/s, Epoch=63, Loss=0.103] \n",
      "100%|██████████| 48/48 [00:00<00:00, 143.95it/s, Epoch=64, Loss=0.102] \n",
      "100%|██████████| 48/48 [00:00<00:00, 138.57it/s, Epoch=65, Loss=0.0973]\n",
      "100%|██████████| 48/48 [00:00<00:00, 157.01it/s, Epoch=66, Loss=0.097] \n",
      "100%|██████████| 48/48 [00:00<00:00, 154.35it/s, Epoch=67, Loss=0.0983]\n",
      "100%|██████████| 48/48 [00:00<00:00, 140.86it/s, Epoch=68, Loss=0.0948]\n",
      "100%|██████████| 48/48 [00:00<00:00, 156.19it/s, Epoch=69, Loss=0.093] \n",
      "100%|██████████| 48/48 [00:00<00:00, 230.88it/s, Epoch=70, Loss=0.0948]\n",
      "100%|██████████| 48/48 [00:00<00:00, 157.25it/s, Epoch=71, Loss=0.0916]\n",
      "100%|██████████| 48/48 [00:00<00:00, 130.32it/s, Epoch=72, Loss=0.092] \n",
      "100%|██████████| 48/48 [00:00<00:00, 140.08it/s, Epoch=73, Loss=0.0924]\n",
      "100%|██████████| 48/48 [00:00<00:00, 170.37it/s, Epoch=74, Loss=0.0903]\n",
      "100%|██████████| 48/48 [00:00<00:00, 138.06it/s, Epoch=75, Loss=0.088] \n",
      "100%|██████████| 48/48 [00:00<00:00, 137.54it/s, Epoch=76, Loss=0.085] \n",
      "100%|██████████| 48/48 [00:00<00:00, 149.93it/s, Epoch=77, Loss=0.0848]\n",
      "100%|██████████| 48/48 [00:00<00:00, 146.08it/s, Epoch=78, Loss=0.091] \n",
      "100%|██████████| 48/48 [00:00<00:00, 169.46it/s, Epoch=79, Loss=0.086] \n",
      "100%|██████████| 48/48 [00:00<00:00, 153.14it/s, Epoch=80, Loss=0.0832]\n",
      "100%|██████████| 48/48 [00:00<00:00, 139.18it/s, Epoch=81, Loss=0.0793]\n",
      "100%|██████████| 48/48 [00:00<00:00, 142.62it/s, Epoch=82, Loss=0.0866]\n",
      "100%|██████████| 48/48 [00:00<00:00, 144.22it/s, Epoch=83, Loss=0.0828]\n",
      "100%|██████████| 48/48 [00:00<00:00, 132.78it/s, Epoch=84, Loss=0.077] \n",
      "100%|██████████| 48/48 [00:00<00:00, 144.41it/s, Epoch=85, Loss=0.0816]\n",
      "100%|██████████| 48/48 [00:00<00:00, 148.35it/s, Epoch=86, Loss=0.0809]\n",
      "100%|██████████| 48/48 [00:00<00:00, 155.43it/s, Epoch=87, Loss=0.0826]\n",
      "100%|██████████| 48/48 [00:00<00:00, 139.16it/s, Epoch=88, Loss=0.0798]\n",
      "100%|██████████| 48/48 [00:00<00:00, 170.33it/s, Epoch=89, Loss=0.0779]\n",
      "100%|██████████| 48/48 [00:00<00:00, 160.37it/s, Epoch=90, Loss=0.076] \n",
      "100%|██████████| 48/48 [00:00<00:00, 162.26it/s, Epoch=91, Loss=0.0739]\n",
      "100%|██████████| 48/48 [00:00<00:00, 143.74it/s, Epoch=92, Loss=0.0774]\n",
      "100%|██████████| 48/48 [00:00<00:00, 160.01it/s, Epoch=93, Loss=0.0747]\n",
      "100%|██████████| 48/48 [00:00<00:00, 160.65it/s, Epoch=94, Loss=0.0764]\n",
      "100%|██████████| 48/48 [00:00<00:00, 159.68it/s, Epoch=95, Loss=0.0748]\n",
      "100%|██████████| 48/48 [00:00<00:00, 155.35it/s, Epoch=96, Loss=0.0716]\n",
      "100%|██████████| 48/48 [00:00<00:00, 164.98it/s, Epoch=97, Loss=0.0752]\n",
      "100%|██████████| 48/48 [00:00<00:00, 165.24it/s, Epoch=98, Loss=0.0773]\n",
      "100%|██████████| 48/48 [00:00<00:00, 160.50it/s, Epoch=99, Loss=0.0716]\n",
      "100%|██████████| 48/48 [00:00<00:00, 174.74it/s, Epoch=0, Loss=0.784]\n",
      "100%|██████████| 48/48 [00:00<00:00, 202.23it/s, Epoch=1, Loss=0.525]\n",
      "100%|██████████| 48/48 [00:00<00:00, 161.77it/s, Epoch=2, Loss=0.438]\n",
      "100%|██████████| 48/48 [00:00<00:00, 141.35it/s, Epoch=3, Loss=0.389]\n",
      "100%|██████████| 48/48 [00:00<00:00, 159.58it/s, Epoch=4, Loss=0.349]\n",
      "100%|██████████| 48/48 [00:00<00:00, 191.82it/s, Epoch=5, Loss=0.323]\n",
      "100%|██████████| 48/48 [00:00<00:00, 170.83it/s, Epoch=6, Loss=0.301]\n",
      "100%|██████████| 48/48 [00:00<00:00, 176.87it/s, Epoch=7, Loss=0.295]\n",
      "100%|██████████| 48/48 [00:00<00:00, 194.08it/s, Epoch=8, Loss=0.275]\n",
      "100%|██████████| 48/48 [00:00<00:00, 182.20it/s, Epoch=9, Loss=0.258]\n",
      "100%|██████████| 48/48 [00:00<00:00, 194.23it/s, Epoch=10, Loss=0.258]\n",
      "100%|██████████| 48/48 [00:00<00:00, 179.32it/s, Epoch=11, Loss=0.248]\n",
      "100%|██████████| 48/48 [00:00<00:00, 156.56it/s, Epoch=12, Loss=0.234]\n",
      "100%|██████████| 48/48 [00:00<00:00, 172.18it/s, Epoch=13, Loss=0.225]\n",
      "100%|██████████| 48/48 [00:00<00:00, 156.28it/s, Epoch=14, Loss=0.226]\n",
      "100%|██████████| 48/48 [00:00<00:00, 186.32it/s, Epoch=15, Loss=0.217]\n",
      "100%|██████████| 48/48 [00:00<00:00, 186.94it/s, Epoch=16, Loss=0.222]\n",
      "100%|██████████| 48/48 [00:00<00:00, 144.17it/s, Epoch=17, Loss=0.211]\n",
      "100%|██████████| 48/48 [00:00<00:00, 145.90it/s, Epoch=18, Loss=0.2]  \n",
      "100%|██████████| 48/48 [00:00<00:00, 132.53it/s, Epoch=19, Loss=0.2]  \n",
      "100%|██████████| 48/48 [00:00<00:00, 150.64it/s, Epoch=20, Loss=0.198]\n",
      "100%|██████████| 48/48 [00:00<00:00, 153.34it/s, Epoch=21, Loss=0.187]\n",
      "100%|██████████| 48/48 [00:00<00:00, 143.89it/s, Epoch=22, Loss=0.19] \n",
      "100%|██████████| 48/48 [00:00<00:00, 134.49it/s, Epoch=23, Loss=0.189]\n",
      "100%|██████████| 48/48 [00:00<00:00, 131.63it/s, Epoch=24, Loss=0.18] \n",
      "100%|██████████| 48/48 [00:00<00:00, 156.14it/s, Epoch=25, Loss=0.17] \n",
      "100%|██████████| 48/48 [00:00<00:00, 130.13it/s, Epoch=26, Loss=0.175]\n",
      "100%|██████████| 48/48 [00:00<00:00, 166.48it/s, Epoch=27, Loss=0.168]\n",
      "100%|██████████| 48/48 [00:00<00:00, 140.88it/s, Epoch=28, Loss=0.18] \n",
      "100%|██████████| 48/48 [00:00<00:00, 172.22it/s, Epoch=29, Loss=0.162]\n",
      "100%|██████████| 48/48 [00:00<00:00, 134.04it/s, Epoch=30, Loss=0.159]\n",
      "100%|██████████| 48/48 [00:00<00:00, 159.28it/s, Epoch=31, Loss=0.159]\n",
      "100%|██████████| 48/48 [00:00<00:00, 150.03it/s, Epoch=32, Loss=0.152]\n",
      "100%|██████████| 48/48 [00:00<00:00, 152.19it/s, Epoch=33, Loss=0.152]\n",
      "100%|██████████| 48/48 [00:00<00:00, 131.41it/s, Epoch=34, Loss=0.145]\n",
      "100%|██████████| 48/48 [00:00<00:00, 162.16it/s, Epoch=35, Loss=0.151]\n",
      "100%|██████████| 48/48 [00:00<00:00, 166.21it/s, Epoch=36, Loss=0.141]\n",
      "100%|██████████| 48/48 [00:00<00:00, 156.87it/s, Epoch=37, Loss=0.142]\n",
      "100%|██████████| 48/48 [00:00<00:00, 168.50it/s, Epoch=38, Loss=0.138]\n",
      "100%|██████████| 48/48 [00:00<00:00, 139.89it/s, Epoch=39, Loss=0.139]\n",
      "100%|██████████| 48/48 [00:00<00:00, 151.40it/s, Epoch=40, Loss=0.132]\n",
      "100%|██████████| 48/48 [00:00<00:00, 151.37it/s, Epoch=41, Loss=0.131]\n",
      "100%|██████████| 48/48 [00:00<00:00, 126.93it/s, Epoch=42, Loss=0.133]\n",
      "100%|██████████| 48/48 [00:00<00:00, 155.87it/s, Epoch=43, Loss=0.128]\n",
      "100%|██████████| 48/48 [00:00<00:00, 194.95it/s, Epoch=44, Loss=0.124]\n",
      "100%|██████████| 48/48 [00:00<00:00, 167.17it/s, Epoch=45, Loss=0.136]\n",
      "100%|██████████| 48/48 [00:00<00:00, 154.57it/s, Epoch=46, Loss=0.126]\n",
      "100%|██████████| 48/48 [00:00<00:00, 177.29it/s, Epoch=47, Loss=0.118]\n",
      "100%|██████████| 48/48 [00:00<00:00, 136.69it/s, Epoch=48, Loss=0.117]\n",
      "100%|██████████| 48/48 [00:00<00:00, 173.69it/s, Epoch=49, Loss=0.118]\n",
      "100%|██████████| 48/48 [00:00<00:00, 145.55it/s, Epoch=50, Loss=0.111] \n",
      "100%|██████████| 48/48 [00:00<00:00, 143.39it/s, Epoch=51, Loss=0.112]\n",
      "100%|██████████| 48/48 [00:00<00:00, 135.81it/s, Epoch=52, Loss=0.111]\n",
      "100%|██████████| 48/48 [00:00<00:00, 168.59it/s, Epoch=53, Loss=0.107] \n",
      "100%|██████████| 48/48 [00:00<00:00, 141.54it/s, Epoch=54, Loss=0.103]\n",
      "100%|██████████| 48/48 [00:00<00:00, 159.01it/s, Epoch=55, Loss=0.107] \n",
      "100%|██████████| 48/48 [00:00<00:00, 142.60it/s, Epoch=56, Loss=0.105]\n",
      "100%|██████████| 48/48 [00:00<00:00, 133.45it/s, Epoch=57, Loss=0.111]\n",
      "100%|██████████| 48/48 [00:00<00:00, 191.75it/s, Epoch=58, Loss=0.0986]\n",
      "100%|██████████| 48/48 [00:00<00:00, 174.89it/s, Epoch=59, Loss=0.0966]\n",
      "100%|██████████| 48/48 [00:00<00:00, 145.38it/s, Epoch=60, Loss=0.0965]\n",
      "100%|██████████| 48/48 [00:00<00:00, 155.36it/s, Epoch=61, Loss=0.1]   \n",
      "100%|██████████| 48/48 [00:00<00:00, 138.39it/s, Epoch=62, Loss=0.0969]\n",
      "100%|██████████| 48/48 [00:00<00:00, 141.52it/s, Epoch=63, Loss=0.0932]\n",
      "100%|██████████| 48/48 [00:00<00:00, 138.71it/s, Epoch=64, Loss=0.0965]\n",
      "100%|██████████| 48/48 [00:00<00:00, 149.09it/s, Epoch=65, Loss=0.0948]\n",
      "100%|██████████| 48/48 [00:00<00:00, 134.76it/s, Epoch=66, Loss=0.0975]\n",
      "100%|██████████| 48/48 [00:00<00:00, 135.78it/s, Epoch=67, Loss=0.0948]\n",
      "100%|██████████| 48/48 [00:00<00:00, 152.91it/s, Epoch=68, Loss=0.0891]\n",
      "100%|██████████| 48/48 [00:00<00:00, 133.62it/s, Epoch=69, Loss=0.0856]\n",
      "100%|██████████| 48/48 [00:00<00:00, 156.99it/s, Epoch=70, Loss=0.0886]\n",
      "100%|██████████| 48/48 [00:00<00:00, 179.74it/s, Epoch=71, Loss=0.0834]\n",
      "100%|██████████| 48/48 [00:00<00:00, 165.13it/s, Epoch=72, Loss=0.0859]\n",
      "100%|██████████| 48/48 [00:00<00:00, 154.18it/s, Epoch=73, Loss=0.0785]\n",
      "100%|██████████| 48/48 [00:00<00:00, 135.59it/s, Epoch=74, Loss=0.0847]\n",
      "100%|██████████| 48/48 [00:00<00:00, 169.19it/s, Epoch=75, Loss=0.0818]\n",
      "100%|██████████| 48/48 [00:00<00:00, 150.81it/s, Epoch=76, Loss=0.0782]\n",
      "100%|██████████| 48/48 [00:00<00:00, 151.69it/s, Epoch=77, Loss=0.0763]\n",
      "100%|██████████| 48/48 [00:00<00:00, 174.84it/s, Epoch=78, Loss=0.0775]\n",
      "100%|██████████| 48/48 [00:00<00:00, 138.41it/s, Epoch=79, Loss=0.0767]\n",
      "100%|██████████| 48/48 [00:00<00:00, 151.74it/s, Epoch=80, Loss=0.0765]\n",
      "100%|██████████| 48/48 [00:00<00:00, 133.68it/s, Epoch=81, Loss=0.0767]\n",
      "100%|██████████| 48/48 [00:00<00:00, 142.24it/s, Epoch=82, Loss=0.0741]\n",
      "100%|██████████| 48/48 [00:00<00:00, 158.11it/s, Epoch=83, Loss=0.0729]\n",
      "100%|██████████| 48/48 [00:00<00:00, 131.67it/s, Epoch=84, Loss=0.073] \n",
      "100%|██████████| 48/48 [00:00<00:00, 153.97it/s, Epoch=85, Loss=0.0753]\n",
      "100%|██████████| 48/48 [00:00<00:00, 184.01it/s, Epoch=86, Loss=0.0742]\n",
      "100%|██████████| 48/48 [00:00<00:00, 143.23it/s, Epoch=87, Loss=0.0717]\n",
      "100%|██████████| 48/48 [00:00<00:00, 171.40it/s, Epoch=88, Loss=0.0685]\n",
      "100%|██████████| 48/48 [00:00<00:00, 141.31it/s, Epoch=89, Loss=0.0652]\n",
      "100%|██████████| 48/48 [00:00<00:00, 167.70it/s, Epoch=90, Loss=0.071] \n",
      "100%|██████████| 48/48 [00:00<00:00, 154.06it/s, Epoch=91, Loss=0.0649]\n",
      "100%|██████████| 48/48 [00:00<00:00, 147.90it/s, Epoch=92, Loss=0.0687]\n",
      "100%|██████████| 48/48 [00:00<00:00, 168.95it/s, Epoch=93, Loss=0.066] \n",
      "100%|██████████| 48/48 [00:00<00:00, 171.83it/s, Epoch=94, Loss=0.0673]\n",
      "100%|██████████| 48/48 [00:00<00:00, 142.11it/s, Epoch=95, Loss=0.0686]\n",
      "100%|██████████| 48/48 [00:00<00:00, 185.87it/s, Epoch=96, Loss=0.0664]\n",
      "100%|██████████| 48/48 [00:00<00:00, 146.72it/s, Epoch=97, Loss=0.0662]\n",
      "100%|██████████| 48/48 [00:00<00:00, 140.04it/s, Epoch=98, Loss=0.0608]\n",
      "100%|██████████| 48/48 [00:00<00:00, 139.09it/s, Epoch=99, Loss=0.0625]\n"
     ]
    }
   ],
   "source": [
    "clf3_100 = MLPClassifier(1152, 4).to(device)\n",
    "train_model(clf3_100, data_3samples, 100, 100)\n",
    "\n",
    "clf3_300 = MLPClassifier(1152, 4).to(device)\n",
    "train_model(clf3_300, data_3samples, 300, 100)\n",
    "\n",
    "clf3_500 = MLPClassifier(1152, 4).to(device)\n",
    "train_model(clf3_500, data_3samples, 500, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e40b9dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:00<00:00, 161.41it/s, Epoch=0, Loss=0.475]\n",
      "100%|██████████| 160/160 [00:01<00:00, 147.21it/s, Epoch=1, Loss=0.283]\n",
      "100%|██████████| 160/160 [00:01<00:00, 148.97it/s, Epoch=2, Loss=0.24] \n",
      "100%|██████████| 160/160 [00:01<00:00, 158.27it/s, Epoch=3, Loss=0.214]\n",
      "100%|██████████| 160/160 [00:01<00:00, 138.45it/s, Epoch=4, Loss=0.201]\n",
      "100%|██████████| 160/160 [00:01<00:00, 157.77it/s, Epoch=5, Loss=0.184]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.23it/s, Epoch=6, Loss=0.182]\n",
      "100%|██████████| 160/160 [00:01<00:00, 138.71it/s, Epoch=7, Loss=0.172]\n",
      "100%|██████████| 160/160 [00:01<00:00, 143.88it/s, Epoch=8, Loss=0.166]\n",
      "100%|██████████| 160/160 [00:00<00:00, 171.59it/s, Epoch=9, Loss=0.159]\n",
      "100%|██████████| 160/160 [00:01<00:00, 141.74it/s, Epoch=10, Loss=0.159]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.86it/s, Epoch=11, Loss=0.153]\n",
      "100%|██████████| 160/160 [00:01<00:00, 153.51it/s, Epoch=12, Loss=0.148]\n",
      "100%|██████████| 160/160 [00:01<00:00, 141.26it/s, Epoch=13, Loss=0.151]\n",
      "100%|██████████| 160/160 [00:01<00:00, 154.75it/s, Epoch=14, Loss=0.143]\n",
      "100%|██████████| 160/160 [00:01<00:00, 148.11it/s, Epoch=15, Loss=0.142]\n",
      "100%|██████████| 160/160 [00:01<00:00, 158.84it/s, Epoch=16, Loss=0.141]\n",
      "100%|██████████| 160/160 [00:01<00:00, 150.87it/s, Epoch=17, Loss=0.14] \n",
      "100%|██████████| 160/160 [00:00<00:00, 161.41it/s, Epoch=18, Loss=0.134]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.35it/s, Epoch=19, Loss=0.131]\n",
      "100%|██████████| 160/160 [00:01<00:00, 143.92it/s, Epoch=20, Loss=0.131]\n",
      "100%|██████████| 160/160 [00:00<00:00, 176.49it/s, Epoch=21, Loss=0.129]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.52it/s, Epoch=22, Loss=0.124]\n",
      "100%|██████████| 160/160 [00:01<00:00, 141.46it/s, Epoch=23, Loss=0.126]\n",
      "100%|██████████| 160/160 [00:00<00:00, 171.12it/s, Epoch=24, Loss=0.125]\n",
      "100%|██████████| 160/160 [00:00<00:00, 174.56it/s, Epoch=25, Loss=0.125]\n",
      "100%|██████████| 160/160 [00:01<00:00, 146.54it/s, Epoch=26, Loss=0.121]\n",
      "100%|██████████| 160/160 [00:01<00:00, 151.38it/s, Epoch=27, Loss=0.121]\n",
      "100%|██████████| 160/160 [00:01<00:00, 150.19it/s, Epoch=28, Loss=0.116]\n",
      "100%|██████████| 160/160 [00:01<00:00, 152.46it/s, Epoch=29, Loss=0.117]\n",
      "100%|██████████| 160/160 [00:00<00:00, 167.64it/s, Epoch=30, Loss=0.116]\n",
      "100%|██████████| 160/160 [00:01<00:00, 153.44it/s, Epoch=31, Loss=0.113]\n",
      "100%|██████████| 160/160 [00:00<00:00, 180.74it/s, Epoch=32, Loss=0.112]\n",
      "100%|██████████| 160/160 [00:00<00:00, 176.13it/s, Epoch=33, Loss=0.113]\n",
      "100%|██████████| 160/160 [00:00<00:00, 170.20it/s, Epoch=34, Loss=0.11] \n",
      "100%|██████████| 160/160 [00:00<00:00, 183.47it/s, Epoch=35, Loss=0.109]\n",
      "100%|██████████| 160/160 [00:00<00:00, 172.92it/s, Epoch=36, Loss=0.108]\n",
      "100%|██████████| 160/160 [00:00<00:00, 179.62it/s, Epoch=37, Loss=0.107]\n",
      "100%|██████████| 160/160 [00:01<00:00, 159.52it/s, Epoch=38, Loss=0.105]\n",
      "100%|██████████| 160/160 [00:00<00:00, 160.91it/s, Epoch=39, Loss=0.106]\n",
      "100%|██████████| 160/160 [00:01<00:00, 158.28it/s, Epoch=40, Loss=0.102]\n",
      "100%|██████████| 160/160 [00:01<00:00, 139.70it/s, Epoch=41, Loss=0.104]\n",
      "100%|██████████| 160/160 [00:01<00:00, 144.87it/s, Epoch=42, Loss=0.102]\n",
      "100%|██████████| 160/160 [00:01<00:00, 147.55it/s, Epoch=43, Loss=0.102] \n",
      "100%|██████████| 160/160 [00:01<00:00, 152.81it/s, Epoch=44, Loss=0.0989]\n",
      "100%|██████████| 160/160 [00:01<00:00, 148.72it/s, Epoch=45, Loss=0.099] \n",
      "100%|██████████| 160/160 [00:01<00:00, 152.92it/s, Epoch=46, Loss=0.0991]\n",
      "100%|██████████| 160/160 [00:01<00:00, 147.81it/s, Epoch=47, Loss=0.0955]\n",
      "100%|██████████| 160/160 [00:01<00:00, 148.87it/s, Epoch=48, Loss=0.095] \n",
      "100%|██████████| 160/160 [00:01<00:00, 144.43it/s, Epoch=49, Loss=0.0964]\n",
      "100%|██████████| 160/160 [00:01<00:00, 150.28it/s, Epoch=50, Loss=0.0953]\n",
      "100%|██████████| 160/160 [00:01<00:00, 143.75it/s, Epoch=51, Loss=0.093] \n",
      "100%|██████████| 160/160 [00:00<00:00, 161.41it/s, Epoch=52, Loss=0.0929]\n",
      "100%|██████████| 160/160 [00:00<00:00, 160.07it/s, Epoch=53, Loss=0.091] \n",
      "100%|██████████| 160/160 [00:01<00:00, 141.92it/s, Epoch=54, Loss=0.0893]\n",
      "100%|██████████| 160/160 [00:01<00:00, 158.52it/s, Epoch=55, Loss=0.0886]\n",
      "100%|██████████| 160/160 [00:01<00:00, 149.42it/s, Epoch=56, Loss=0.0888]\n",
      "100%|██████████| 160/160 [00:01<00:00, 149.75it/s, Epoch=57, Loss=0.0883]\n",
      "100%|██████████| 160/160 [00:01<00:00, 156.81it/s, Epoch=58, Loss=0.0871]\n",
      "100%|██████████| 160/160 [00:00<00:00, 165.93it/s, Epoch=59, Loss=0.088] \n",
      "100%|██████████| 160/160 [00:01<00:00, 159.42it/s, Epoch=60, Loss=0.0868]\n",
      "100%|██████████| 160/160 [00:01<00:00, 143.63it/s, Epoch=61, Loss=0.0851]\n",
      "100%|██████████| 160/160 [00:01<00:00, 143.05it/s, Epoch=62, Loss=0.0845]\n",
      "100%|██████████| 160/160 [00:01<00:00, 144.77it/s, Epoch=63, Loss=0.0833]\n",
      "100%|██████████| 160/160 [00:01<00:00, 152.62it/s, Epoch=64, Loss=0.082] \n",
      "100%|██████████| 160/160 [00:01<00:00, 151.68it/s, Epoch=65, Loss=0.0818]\n",
      "100%|██████████| 160/160 [00:01<00:00, 143.30it/s, Epoch=66, Loss=0.0799]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.35it/s, Epoch=67, Loss=0.0799]\n",
      "100%|██████████| 160/160 [00:01<00:00, 138.03it/s, Epoch=68, Loss=0.0792]\n",
      "100%|██████████| 160/160 [00:01<00:00, 153.37it/s, Epoch=69, Loss=0.0787]\n",
      "100%|██████████| 160/160 [00:01<00:00, 142.84it/s, Epoch=70, Loss=0.0795]\n",
      "100%|██████████| 160/160 [00:01<00:00, 156.91it/s, Epoch=71, Loss=0.0801]\n",
      "100%|██████████| 160/160 [00:01<00:00, 151.32it/s, Epoch=72, Loss=0.0801]\n",
      "100%|██████████| 160/160 [00:01<00:00, 138.04it/s, Epoch=73, Loss=0.0782]\n",
      "100%|██████████| 160/160 [00:01<00:00, 137.50it/s, Epoch=74, Loss=0.0778]\n",
      "100%|██████████| 160/160 [00:01<00:00, 156.60it/s, Epoch=75, Loss=0.0752]\n",
      "100%|██████████| 160/160 [00:01<00:00, 149.83it/s, Epoch=76, Loss=0.0767]\n",
      "100%|██████████| 160/160 [00:00<00:00, 166.87it/s, Epoch=77, Loss=0.0725]\n",
      "100%|██████████| 160/160 [00:00<00:00, 172.35it/s, Epoch=78, Loss=0.0744]\n",
      "100%|██████████| 160/160 [00:00<00:00, 177.52it/s, Epoch=79, Loss=0.0762]\n",
      "100%|██████████| 160/160 [00:00<00:00, 174.45it/s, Epoch=80, Loss=0.0722]\n",
      "100%|██████████| 160/160 [00:01<00:00, 147.31it/s, Epoch=81, Loss=0.0738]\n",
      "100%|██████████| 160/160 [00:01<00:00, 143.06it/s, Epoch=82, Loss=0.0732]\n",
      "100%|██████████| 160/160 [00:01<00:00, 146.58it/s, Epoch=83, Loss=0.0727]\n",
      "100%|██████████| 160/160 [00:01<00:00, 140.98it/s, Epoch=84, Loss=0.0723]\n",
      "100%|██████████| 160/160 [00:01<00:00, 147.87it/s, Epoch=85, Loss=0.0703]\n",
      "100%|██████████| 160/160 [00:01<00:00, 141.33it/s, Epoch=86, Loss=0.0705]\n",
      "100%|██████████| 160/160 [00:01<00:00, 146.97it/s, Epoch=87, Loss=0.0681]\n",
      "100%|██████████| 160/160 [00:01<00:00, 151.05it/s, Epoch=88, Loss=0.0704]\n",
      "100%|██████████| 160/160 [00:01<00:00, 157.17it/s, Epoch=89, Loss=0.0697]\n",
      "100%|██████████| 160/160 [00:01<00:00, 153.22it/s, Epoch=90, Loss=0.0696]\n",
      "100%|██████████| 160/160 [00:01<00:00, 147.99it/s, Epoch=91, Loss=0.0676]\n",
      "100%|██████████| 160/160 [00:01<00:00, 146.08it/s, Epoch=92, Loss=0.066] \n",
      "100%|██████████| 160/160 [00:01<00:00, 142.04it/s, Epoch=93, Loss=0.068] \n",
      "100%|██████████| 160/160 [00:00<00:00, 168.55it/s, Epoch=94, Loss=0.0674]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.72it/s, Epoch=95, Loss=0.0688]\n",
      "100%|██████████| 160/160 [00:00<00:00, 172.56it/s, Epoch=96, Loss=0.0655]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.26it/s, Epoch=97, Loss=0.0665]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.09it/s, Epoch=98, Loss=0.066] \n",
      "100%|██████████| 160/160 [00:01<00:00, 146.72it/s, Epoch=99, Loss=0.0656]\n",
      "100%|██████████| 160/160 [00:01<00:00, 149.75it/s, Epoch=0, Loss=0.578]\n",
      "100%|██████████| 160/160 [00:00<00:00, 179.17it/s, Epoch=1, Loss=0.345]\n",
      "100%|██████████| 160/160 [00:00<00:00, 183.87it/s, Epoch=2, Loss=0.282]\n",
      "100%|██████████| 160/160 [00:00<00:00, 176.43it/s, Epoch=3, Loss=0.248]\n",
      "100%|██████████| 160/160 [00:00<00:00, 170.50it/s, Epoch=4, Loss=0.229]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.03it/s, Epoch=5, Loss=0.217]\n",
      "100%|██████████| 160/160 [00:01<00:00, 158.80it/s, Epoch=6, Loss=0.209]\n",
      "100%|██████████| 160/160 [00:00<00:00, 173.09it/s, Epoch=7, Loss=0.198]\n",
      "100%|██████████| 160/160 [00:00<00:00, 177.62it/s, Epoch=8, Loss=0.192]\n",
      "100%|██████████| 160/160 [00:00<00:00, 160.93it/s, Epoch=9, Loss=0.191]\n",
      "100%|██████████| 160/160 [00:00<00:00, 168.68it/s, Epoch=10, Loss=0.184]\n",
      "100%|██████████| 160/160 [00:00<00:00, 169.94it/s, Epoch=11, Loss=0.177]\n",
      "100%|██████████| 160/160 [00:00<00:00, 160.29it/s, Epoch=12, Loss=0.173]\n",
      "100%|██████████| 160/160 [00:00<00:00, 166.11it/s, Epoch=13, Loss=0.171]\n",
      "100%|██████████| 160/160 [00:00<00:00, 168.12it/s, Epoch=14, Loss=0.163]\n",
      "100%|██████████| 160/160 [00:00<00:00, 180.84it/s, Epoch=15, Loss=0.159]\n",
      "100%|██████████| 160/160 [00:00<00:00, 178.15it/s, Epoch=16, Loss=0.159]\n",
      "100%|██████████| 160/160 [00:00<00:00, 178.18it/s, Epoch=17, Loss=0.16] \n",
      "100%|██████████| 160/160 [00:00<00:00, 165.99it/s, Epoch=18, Loss=0.155]\n",
      "100%|██████████| 160/160 [00:01<00:00, 159.95it/s, Epoch=19, Loss=0.15] \n",
      "100%|██████████| 160/160 [00:01<00:00, 155.68it/s, Epoch=20, Loss=0.144]\n",
      "100%|██████████| 160/160 [00:00<00:00, 170.95it/s, Epoch=21, Loss=0.146]\n",
      "100%|██████████| 160/160 [00:00<00:00, 165.64it/s, Epoch=22, Loss=0.142]\n",
      "100%|██████████| 160/160 [00:01<00:00, 157.06it/s, Epoch=23, Loss=0.142]\n",
      "100%|██████████| 160/160 [00:01<00:00, 154.12it/s, Epoch=24, Loss=0.138]\n",
      "100%|██████████| 160/160 [00:01<00:00, 156.62it/s, Epoch=25, Loss=0.138]\n",
      "100%|██████████| 160/160 [00:01<00:00, 157.60it/s, Epoch=26, Loss=0.132]\n",
      "100%|██████████| 160/160 [00:01<00:00, 152.31it/s, Epoch=27, Loss=0.128]\n",
      "100%|██████████| 160/160 [00:01<00:00, 139.15it/s, Epoch=28, Loss=0.136]\n",
      "100%|██████████| 160/160 [00:01<00:00, 140.43it/s, Epoch=29, Loss=0.127]\n",
      "100%|██████████| 160/160 [00:01<00:00, 147.22it/s, Epoch=30, Loss=0.125]\n",
      "100%|██████████| 160/160 [00:01<00:00, 154.87it/s, Epoch=31, Loss=0.124]\n",
      "100%|██████████| 160/160 [00:01<00:00, 154.73it/s, Epoch=32, Loss=0.12] \n",
      "100%|██████████| 160/160 [00:00<00:00, 165.69it/s, Epoch=33, Loss=0.124]\n",
      "100%|██████████| 160/160 [00:01<00:00, 142.14it/s, Epoch=34, Loss=0.119]\n",
      "100%|██████████| 160/160 [00:01<00:00, 141.15it/s, Epoch=35, Loss=0.121]\n",
      "100%|██████████| 160/160 [00:01<00:00, 154.08it/s, Epoch=36, Loss=0.119]\n",
      "100%|██████████| 160/160 [00:01<00:00, 146.47it/s, Epoch=37, Loss=0.116]\n",
      "100%|██████████| 160/160 [00:01<00:00, 140.99it/s, Epoch=38, Loss=0.115]\n",
      "100%|██████████| 160/160 [00:00<00:00, 168.39it/s, Epoch=39, Loss=0.111]\n",
      "100%|██████████| 160/160 [00:01<00:00, 145.21it/s, Epoch=40, Loss=0.11] \n",
      "100%|██████████| 160/160 [00:01<00:00, 155.46it/s, Epoch=41, Loss=0.11] \n",
      "100%|██████████| 160/160 [00:01<00:00, 148.00it/s, Epoch=42, Loss=0.108]\n",
      "100%|██████████| 160/160 [00:01<00:00, 138.46it/s, Epoch=43, Loss=0.11] \n",
      "100%|██████████| 160/160 [00:01<00:00, 149.15it/s, Epoch=44, Loss=0.105]\n",
      "100%|██████████| 160/160 [00:01<00:00, 142.84it/s, Epoch=45, Loss=0.104]\n",
      "100%|██████████| 160/160 [00:01<00:00, 147.38it/s, Epoch=46, Loss=0.103]\n",
      "100%|██████████| 160/160 [00:00<00:00, 172.22it/s, Epoch=47, Loss=0.101] \n",
      "100%|██████████| 160/160 [00:01<00:00, 146.02it/s, Epoch=48, Loss=0.101] \n",
      "100%|██████████| 160/160 [00:01<00:00, 143.60it/s, Epoch=49, Loss=0.101]\n",
      "100%|██████████| 160/160 [00:01<00:00, 136.13it/s, Epoch=50, Loss=0.0973]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.71it/s, Epoch=51, Loss=0.0987]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.52it/s, Epoch=52, Loss=0.096] \n",
      "100%|██████████| 160/160 [00:01<00:00, 145.30it/s, Epoch=53, Loss=0.0957]\n",
      "100%|██████████| 160/160 [00:01<00:00, 145.73it/s, Epoch=54, Loss=0.0971]\n",
      "100%|██████████| 160/160 [00:01<00:00, 137.58it/s, Epoch=55, Loss=0.0951]\n",
      "100%|██████████| 160/160 [00:01<00:00, 137.69it/s, Epoch=56, Loss=0.092] \n",
      "100%|██████████| 160/160 [00:01<00:00, 149.64it/s, Epoch=57, Loss=0.0917]\n",
      "100%|██████████| 160/160 [00:01<00:00, 157.09it/s, Epoch=58, Loss=0.0872]\n",
      "100%|██████████| 160/160 [00:01<00:00, 146.91it/s, Epoch=59, Loss=0.0921]\n",
      "100%|██████████| 160/160 [00:00<00:00, 175.01it/s, Epoch=60, Loss=0.0869]\n",
      "100%|██████████| 160/160 [00:01<00:00, 154.92it/s, Epoch=61, Loss=0.0882]\n",
      "100%|██████████| 160/160 [00:00<00:00, 173.76it/s, Epoch=62, Loss=0.0845]\n",
      "100%|██████████| 160/160 [00:00<00:00, 180.16it/s, Epoch=63, Loss=0.0829]\n",
      "100%|██████████| 160/160 [00:00<00:00, 171.07it/s, Epoch=64, Loss=0.0843]\n",
      "100%|██████████| 160/160 [00:00<00:00, 164.29it/s, Epoch=65, Loss=0.0859]\n",
      "100%|██████████| 160/160 [00:00<00:00, 164.65it/s, Epoch=66, Loss=0.0841]\n",
      "100%|██████████| 160/160 [00:01<00:00, 158.50it/s, Epoch=67, Loss=0.0827]\n",
      "100%|██████████| 160/160 [00:01<00:00, 153.11it/s, Epoch=68, Loss=0.0818]\n",
      "100%|██████████| 160/160 [00:01<00:00, 156.34it/s, Epoch=69, Loss=0.0797]\n",
      "100%|██████████| 160/160 [00:01<00:00, 152.19it/s, Epoch=70, Loss=0.077] \n",
      "100%|██████████| 160/160 [00:01<00:00, 142.14it/s, Epoch=71, Loss=0.0791]\n",
      "100%|██████████| 160/160 [00:01<00:00, 144.00it/s, Epoch=72, Loss=0.0809]\n",
      "100%|██████████| 160/160 [00:01<00:00, 142.48it/s, Epoch=73, Loss=0.0778]\n",
      "100%|██████████| 160/160 [00:01<00:00, 142.43it/s, Epoch=74, Loss=0.0779]\n",
      "100%|██████████| 160/160 [00:01<00:00, 153.02it/s, Epoch=75, Loss=0.0762]\n",
      "100%|██████████| 160/160 [00:01<00:00, 145.50it/s, Epoch=76, Loss=0.0744]\n",
      "100%|██████████| 160/160 [00:01<00:00, 138.83it/s, Epoch=77, Loss=0.0752]\n",
      "100%|██████████| 160/160 [00:01<00:00, 148.39it/s, Epoch=78, Loss=0.0752]\n",
      "100%|██████████| 160/160 [00:01<00:00, 147.04it/s, Epoch=79, Loss=0.0725]\n",
      "100%|██████████| 160/160 [00:01<00:00, 149.07it/s, Epoch=80, Loss=0.0744]\n",
      "100%|██████████| 160/160 [00:01<00:00, 141.27it/s, Epoch=81, Loss=0.0721]\n",
      "100%|██████████| 160/160 [00:01<00:00, 141.43it/s, Epoch=82, Loss=0.0686]\n",
      "100%|██████████| 160/160 [00:01<00:00, 156.14it/s, Epoch=83, Loss=0.0714]\n",
      "100%|██████████| 160/160 [00:01<00:00, 140.90it/s, Epoch=84, Loss=0.0717]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.35it/s, Epoch=85, Loss=0.0714]\n",
      "100%|██████████| 160/160 [00:01<00:00, 139.23it/s, Epoch=86, Loss=0.0696]\n",
      "100%|██████████| 160/160 [00:01<00:00, 143.60it/s, Epoch=87, Loss=0.0674]\n",
      "100%|██████████| 160/160 [00:01<00:00, 146.26it/s, Epoch=88, Loss=0.0708]\n",
      "100%|██████████| 160/160 [00:00<00:00, 170.01it/s, Epoch=89, Loss=0.0654]\n",
      "100%|██████████| 160/160 [00:01<00:00, 149.77it/s, Epoch=90, Loss=0.0683]\n",
      "100%|██████████| 160/160 [00:01<00:00, 157.54it/s, Epoch=91, Loss=0.0672]\n",
      "100%|██████████| 160/160 [00:01<00:00, 144.34it/s, Epoch=92, Loss=0.0654]\n",
      "100%|██████████| 160/160 [00:01<00:00, 156.83it/s, Epoch=93, Loss=0.0633]\n",
      "100%|██████████| 160/160 [00:01<00:00, 151.41it/s, Epoch=94, Loss=0.0632]\n",
      "100%|██████████| 160/160 [00:01<00:00, 159.84it/s, Epoch=95, Loss=0.066] \n",
      "100%|██████████| 160/160 [00:01<00:00, 154.84it/s, Epoch=96, Loss=0.066] \n",
      "100%|██████████| 160/160 [00:00<00:00, 176.98it/s, Epoch=97, Loss=0.0632]\n",
      "100%|██████████| 160/160 [00:00<00:00, 176.09it/s, Epoch=98, Loss=0.065] \n",
      "100%|██████████| 160/160 [00:00<00:00, 183.59it/s, Epoch=99, Loss=0.0618]\n",
      "100%|██████████| 160/160 [00:00<00:00, 166.03it/s, Epoch=0, Loss=0.619]\n",
      "100%|██████████| 160/160 [00:01<00:00, 143.63it/s, Epoch=1, Loss=0.384]\n",
      "100%|██████████| 160/160 [00:01<00:00, 145.25it/s, Epoch=2, Loss=0.332]\n",
      "100%|██████████| 160/160 [00:01<00:00, 158.68it/s, Epoch=3, Loss=0.297]\n",
      "100%|██████████| 160/160 [00:01<00:00, 140.97it/s, Epoch=4, Loss=0.271]\n",
      "100%|██████████| 160/160 [00:00<00:00, 166.31it/s, Epoch=5, Loss=0.259]\n",
      "100%|██████████| 160/160 [00:00<00:00, 176.59it/s, Epoch=6, Loss=0.247]\n",
      "100%|██████████| 160/160 [00:00<00:00, 193.28it/s, Epoch=7, Loss=0.238]\n",
      "100%|██████████| 160/160 [00:00<00:00, 178.92it/s, Epoch=8, Loss=0.226]\n",
      "100%|██████████| 160/160 [00:00<00:00, 169.52it/s, Epoch=9, Loss=0.224]\n",
      "100%|██████████| 160/160 [00:00<00:00, 160.56it/s, Epoch=10, Loss=0.216]\n",
      "100%|██████████| 160/160 [00:01<00:00, 150.62it/s, Epoch=11, Loss=0.208]\n",
      "100%|██████████| 160/160 [00:01<00:00, 145.27it/s, Epoch=12, Loss=0.207]\n",
      "100%|██████████| 160/160 [00:01<00:00, 138.16it/s, Epoch=13, Loss=0.195]\n",
      "100%|██████████| 160/160 [00:01<00:00, 151.81it/s, Epoch=14, Loss=0.198]\n",
      "100%|██████████| 160/160 [00:01<00:00, 154.43it/s, Epoch=15, Loss=0.192]\n",
      "100%|██████████| 160/160 [00:01<00:00, 144.00it/s, Epoch=16, Loss=0.189]\n",
      "100%|██████████| 160/160 [00:01<00:00, 145.50it/s, Epoch=17, Loss=0.185]\n",
      "100%|██████████| 160/160 [00:01<00:00, 158.96it/s, Epoch=18, Loss=0.181]\n",
      "100%|██████████| 160/160 [00:01<00:00, 149.42it/s, Epoch=19, Loss=0.177]\n",
      "100%|██████████| 160/160 [00:01<00:00, 147.16it/s, Epoch=20, Loss=0.177]\n",
      "100%|██████████| 160/160 [00:01<00:00, 146.38it/s, Epoch=21, Loss=0.18] \n",
      "100%|██████████| 160/160 [00:01<00:00, 153.47it/s, Epoch=22, Loss=0.171]\n",
      "100%|██████████| 160/160 [00:01<00:00, 153.42it/s, Epoch=23, Loss=0.168]\n",
      "100%|██████████| 160/160 [00:01<00:00, 145.24it/s, Epoch=24, Loss=0.167]\n",
      "100%|██████████| 160/160 [00:01<00:00, 144.43it/s, Epoch=25, Loss=0.166]\n",
      "100%|██████████| 160/160 [00:01<00:00, 139.88it/s, Epoch=26, Loss=0.166]\n",
      "100%|██████████| 160/160 [00:01<00:00, 150.87it/s, Epoch=27, Loss=0.159]\n",
      "100%|██████████| 160/160 [00:01<00:00, 142.65it/s, Epoch=28, Loss=0.161]\n",
      "100%|██████████| 160/160 [00:01<00:00, 142.17it/s, Epoch=29, Loss=0.159]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.66it/s, Epoch=30, Loss=0.154]\n",
      "100%|██████████| 160/160 [00:01<00:00, 144.16it/s, Epoch=31, Loss=0.154]\n",
      "100%|██████████| 160/160 [00:01<00:00, 142.03it/s, Epoch=32, Loss=0.148]\n",
      "100%|██████████| 160/160 [00:01<00:00, 149.65it/s, Epoch=33, Loss=0.15] \n",
      "100%|██████████| 160/160 [00:01<00:00, 144.34it/s, Epoch=34, Loss=0.148]\n",
      "100%|██████████| 160/160 [00:00<00:00, 162.00it/s, Epoch=35, Loss=0.147]\n",
      "100%|██████████| 160/160 [00:01<00:00, 159.15it/s, Epoch=36, Loss=0.148]\n",
      "100%|██████████| 160/160 [00:01<00:00, 159.56it/s, Epoch=37, Loss=0.141]\n",
      "100%|██████████| 160/160 [00:01<00:00, 151.01it/s, Epoch=38, Loss=0.141]\n",
      "100%|██████████| 160/160 [00:01<00:00, 139.59it/s, Epoch=39, Loss=0.143]\n",
      "100%|██████████| 160/160 [00:00<00:00, 177.69it/s, Epoch=40, Loss=0.137]\n",
      "100%|██████████| 160/160 [00:00<00:00, 165.09it/s, Epoch=41, Loss=0.137]\n",
      "100%|██████████| 160/160 [00:00<00:00, 175.87it/s, Epoch=42, Loss=0.137]\n",
      "100%|██████████| 160/160 [00:01<00:00, 158.12it/s, Epoch=43, Loss=0.133]\n",
      "100%|██████████| 160/160 [00:01<00:00, 157.57it/s, Epoch=44, Loss=0.133]\n",
      "100%|██████████| 160/160 [00:01<00:00, 143.95it/s, Epoch=45, Loss=0.13] \n",
      "100%|██████████| 160/160 [00:01<00:00, 150.05it/s, Epoch=46, Loss=0.132]\n",
      "100%|██████████| 160/160 [00:01<00:00, 157.30it/s, Epoch=47, Loss=0.129]\n",
      "100%|██████████| 160/160 [00:00<00:00, 163.18it/s, Epoch=48, Loss=0.127]\n",
      "100%|██████████| 160/160 [00:01<00:00, 152.20it/s, Epoch=49, Loss=0.127]\n",
      "100%|██████████| 160/160 [00:01<00:00, 154.89it/s, Epoch=50, Loss=0.125]\n",
      "100%|██████████| 160/160 [00:00<00:00, 162.30it/s, Epoch=51, Loss=0.125]\n",
      "100%|██████████| 160/160 [00:01<00:00, 144.16it/s, Epoch=52, Loss=0.128]\n",
      "100%|██████████| 160/160 [00:01<00:00, 140.84it/s, Epoch=53, Loss=0.123]\n",
      "100%|██████████| 160/160 [00:01<00:00, 147.30it/s, Epoch=54, Loss=0.126]\n",
      "100%|██████████| 160/160 [00:01<00:00, 155.01it/s, Epoch=55, Loss=0.123]\n",
      "100%|██████████| 160/160 [00:01<00:00, 138.64it/s, Epoch=56, Loss=0.12] \n",
      "100%|██████████| 160/160 [00:01<00:00, 147.30it/s, Epoch=57, Loss=0.119]\n",
      "100%|██████████| 160/160 [00:01<00:00, 148.08it/s, Epoch=58, Loss=0.117]\n",
      "100%|██████████| 160/160 [00:01<00:00, 158.54it/s, Epoch=59, Loss=0.118]\n",
      "100%|██████████| 160/160 [00:01<00:00, 150.21it/s, Epoch=60, Loss=0.117]\n",
      "100%|██████████| 160/160 [00:01<00:00, 151.50it/s, Epoch=61, Loss=0.114]\n",
      "100%|██████████| 160/160 [00:01<00:00, 153.40it/s, Epoch=62, Loss=0.114]\n",
      "100%|██████████| 160/160 [00:00<00:00, 173.53it/s, Epoch=63, Loss=0.113]\n",
      "100%|██████████| 160/160 [00:01<00:00, 158.91it/s, Epoch=64, Loss=0.11] \n",
      "100%|██████████| 160/160 [00:01<00:00, 138.39it/s, Epoch=65, Loss=0.108]\n",
      "100%|██████████| 160/160 [00:00<00:00, 163.08it/s, Epoch=66, Loss=0.109]\n",
      "100%|██████████| 160/160 [00:01<00:00, 158.69it/s, Epoch=67, Loss=0.11] \n",
      "100%|██████████| 160/160 [00:01<00:00, 148.47it/s, Epoch=68, Loss=0.11] \n",
      "100%|██████████| 160/160 [00:01<00:00, 147.05it/s, Epoch=69, Loss=0.112]\n",
      "100%|██████████| 160/160 [00:01<00:00, 143.88it/s, Epoch=70, Loss=0.105]\n",
      "100%|██████████| 160/160 [00:01<00:00, 158.86it/s, Epoch=71, Loss=0.105]\n",
      "100%|██████████| 160/160 [00:01<00:00, 141.54it/s, Epoch=72, Loss=0.105]\n",
      "100%|██████████| 160/160 [00:01<00:00, 159.64it/s, Epoch=73, Loss=0.105]\n",
      "100%|██████████| 160/160 [00:01<00:00, 153.32it/s, Epoch=74, Loss=0.101] \n",
      "100%|██████████| 160/160 [00:01<00:00, 141.84it/s, Epoch=75, Loss=0.102]\n",
      "100%|██████████| 160/160 [00:01<00:00, 147.51it/s, Epoch=76, Loss=0.104]\n",
      "100%|██████████| 160/160 [00:01<00:00, 144.50it/s, Epoch=77, Loss=0.0996]\n",
      "100%|██████████| 160/160 [00:01<00:00, 138.79it/s, Epoch=78, Loss=0.0977]\n",
      "100%|██████████| 160/160 [00:01<00:00, 149.81it/s, Epoch=79, Loss=0.1]   \n",
      "100%|██████████| 160/160 [00:01<00:00, 152.61it/s, Epoch=80, Loss=0.0957]\n",
      "100%|██████████| 160/160 [00:01<00:00, 135.13it/s, Epoch=81, Loss=0.0972]\n",
      "100%|██████████| 160/160 [00:01<00:00, 147.09it/s, Epoch=82, Loss=0.0993]\n",
      "100%|██████████| 160/160 [00:00<00:00, 161.53it/s, Epoch=83, Loss=0.0943]\n",
      "100%|██████████| 160/160 [00:00<00:00, 171.59it/s, Epoch=84, Loss=0.0969]\n",
      "100%|██████████| 160/160 [00:01<00:00, 151.73it/s, Epoch=85, Loss=0.0962]\n",
      "100%|██████████| 160/160 [00:01<00:00, 138.42it/s, Epoch=86, Loss=0.0941]\n",
      "100%|██████████| 160/160 [00:01<00:00, 149.94it/s, Epoch=87, Loss=0.0942]\n",
      "100%|██████████| 160/160 [00:01<00:00, 151.49it/s, Epoch=88, Loss=0.0949]\n",
      "100%|██████████| 160/160 [00:01<00:00, 151.03it/s, Epoch=89, Loss=0.093] \n",
      "100%|██████████| 160/160 [00:01<00:00, 146.00it/s, Epoch=90, Loss=0.0908]\n",
      "100%|██████████| 160/160 [00:01<00:00, 141.39it/s, Epoch=91, Loss=0.0911]\n",
      "100%|██████████| 160/160 [00:01<00:00, 144.70it/s, Epoch=92, Loss=0.0905]\n",
      "100%|██████████| 160/160 [00:01<00:00, 145.76it/s, Epoch=93, Loss=0.0892]\n",
      "100%|██████████| 160/160 [00:01<00:00, 144.01it/s, Epoch=94, Loss=0.0916]\n",
      "100%|██████████| 160/160 [00:01<00:00, 144.58it/s, Epoch=95, Loss=0.0888]\n",
      "100%|██████████| 160/160 [00:01<00:00, 158.90it/s, Epoch=96, Loss=0.0868]\n",
      "100%|██████████| 160/160 [00:01<00:00, 148.08it/s, Epoch=97, Loss=0.0877]\n",
      "100%|██████████| 160/160 [00:00<00:00, 166.91it/s, Epoch=98, Loss=0.0882]\n",
      "100%|██████████| 160/160 [00:00<00:00, 163.21it/s, Epoch=99, Loss=0.0891]\n"
     ]
    }
   ],
   "source": [
    "clf10_100 = MLPClassifier(1152, 4).to(device)\n",
    "train_model(clf10_100, data_10samples, 100, 100)\n",
    "\n",
    "clf10_300 = MLPClassifier(1152, 4).to(device)\n",
    "train_model(clf10_300, data_10samples, 300, 100)\n",
    "\n",
    "clf10_500 = MLPClassifier(1152, 4).to(device)\n",
    "train_model(clf10_500, data_10samples, 500, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fb245a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:02<00:00, 149.52it/s, Epoch=0, Loss=0.444]\n",
      "100%|██████████| 320/320 [00:02<00:00, 156.73it/s, Epoch=1, Loss=0.276]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.88it/s, Epoch=2, Loss=0.24] \n",
      "100%|██████████| 320/320 [00:02<00:00, 156.12it/s, Epoch=3, Loss=0.218]\n",
      "100%|██████████| 320/320 [00:02<00:00, 144.23it/s, Epoch=4, Loss=0.204]\n",
      "100%|██████████| 320/320 [00:02<00:00, 154.13it/s, Epoch=5, Loss=0.195]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.99it/s, Epoch=6, Loss=0.185]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.05it/s, Epoch=7, Loss=0.178]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.41it/s, Epoch=8, Loss=0.173]\n",
      "100%|██████████| 320/320 [00:02<00:00, 143.28it/s, Epoch=9, Loss=0.166]\n",
      "100%|██████████| 320/320 [00:02<00:00, 140.43it/s, Epoch=10, Loss=0.163]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.32it/s, Epoch=11, Loss=0.162]\n",
      "100%|██████████| 320/320 [00:02<00:00, 149.45it/s, Epoch=12, Loss=0.157]\n",
      "100%|██████████| 320/320 [00:02<00:00, 149.96it/s, Epoch=13, Loss=0.151]\n",
      "100%|██████████| 320/320 [00:02<00:00, 154.74it/s, Epoch=14, Loss=0.15] \n",
      "100%|██████████| 320/320 [00:02<00:00, 149.66it/s, Epoch=15, Loss=0.147]\n",
      "100%|██████████| 320/320 [00:02<00:00, 155.09it/s, Epoch=16, Loss=0.145]\n",
      "100%|██████████| 320/320 [00:02<00:00, 154.28it/s, Epoch=17, Loss=0.143]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.19it/s, Epoch=18, Loss=0.14] \n",
      "100%|██████████| 320/320 [00:01<00:00, 163.65it/s, Epoch=19, Loss=0.138]\n",
      "100%|██████████| 320/320 [00:02<00:00, 135.94it/s, Epoch=20, Loss=0.136]\n",
      "100%|██████████| 320/320 [00:01<00:00, 160.37it/s, Epoch=21, Loss=0.133]\n",
      "100%|██████████| 320/320 [00:01<00:00, 184.76it/s, Epoch=22, Loss=0.132]\n",
      "100%|██████████| 320/320 [00:01<00:00, 176.55it/s, Epoch=23, Loss=0.132]\n",
      "100%|██████████| 320/320 [00:01<00:00, 181.13it/s, Epoch=24, Loss=0.128]\n",
      "100%|██████████| 320/320 [00:01<00:00, 175.01it/s, Epoch=25, Loss=0.126]\n",
      "100%|██████████| 320/320 [00:02<00:00, 155.09it/s, Epoch=26, Loss=0.126]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.61it/s, Epoch=27, Loss=0.125]\n",
      "100%|██████████| 320/320 [00:02<00:00, 143.29it/s, Epoch=28, Loss=0.121]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.07it/s, Epoch=29, Loss=0.124]\n",
      "100%|██████████| 320/320 [00:02<00:00, 159.19it/s, Epoch=30, Loss=0.122]\n",
      "100%|██████████| 320/320 [00:02<00:00, 149.05it/s, Epoch=31, Loss=0.119]\n",
      "100%|██████████| 320/320 [00:02<00:00, 149.76it/s, Epoch=32, Loss=0.119]\n",
      "100%|██████████| 320/320 [00:01<00:00, 160.19it/s, Epoch=33, Loss=0.117]\n",
      "100%|██████████| 320/320 [00:01<00:00, 160.34it/s, Epoch=34, Loss=0.115]\n",
      "100%|██████████| 320/320 [00:02<00:00, 158.30it/s, Epoch=35, Loss=0.114]\n",
      "100%|██████████| 320/320 [00:02<00:00, 144.48it/s, Epoch=36, Loss=0.114]\n",
      "100%|██████████| 320/320 [00:02<00:00, 159.46it/s, Epoch=37, Loss=0.113]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.75it/s, Epoch=38, Loss=0.111]\n",
      "100%|██████████| 320/320 [00:02<00:00, 156.24it/s, Epoch=39, Loss=0.108]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.56it/s, Epoch=40, Loss=0.109]\n",
      "100%|██████████| 320/320 [00:02<00:00, 145.69it/s, Epoch=41, Loss=0.108]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.54it/s, Epoch=42, Loss=0.107]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.59it/s, Epoch=43, Loss=0.107]\n",
      "100%|██████████| 320/320 [00:02<00:00, 144.28it/s, Epoch=44, Loss=0.103]\n",
      "100%|██████████| 320/320 [00:02<00:00, 141.89it/s, Epoch=45, Loss=0.103]\n",
      "100%|██████████| 320/320 [00:02<00:00, 144.03it/s, Epoch=46, Loss=0.1]   \n",
      "100%|██████████| 320/320 [00:02<00:00, 146.47it/s, Epoch=47, Loss=0.103]\n",
      "100%|██████████| 320/320 [00:02<00:00, 143.99it/s, Epoch=48, Loss=0.103]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.60it/s, Epoch=49, Loss=0.0983]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.80it/s, Epoch=50, Loss=0.0992]\n",
      "100%|██████████| 320/320 [00:02<00:00, 158.00it/s, Epoch=51, Loss=0.0983]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.22it/s, Epoch=52, Loss=0.0979]\n",
      "100%|██████████| 320/320 [00:01<00:00, 163.96it/s, Epoch=53, Loss=0.0959]\n",
      "100%|██████████| 320/320 [00:02<00:00, 142.56it/s, Epoch=54, Loss=0.0964]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.55it/s, Epoch=55, Loss=0.0954]\n",
      "100%|██████████| 320/320 [00:01<00:00, 163.33it/s, Epoch=56, Loss=0.0947]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.28it/s, Epoch=57, Loss=0.0958]\n",
      "100%|██████████| 320/320 [00:02<00:00, 158.14it/s, Epoch=58, Loss=0.0937]\n",
      "100%|██████████| 320/320 [00:02<00:00, 143.63it/s, Epoch=59, Loss=0.0902]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.36it/s, Epoch=60, Loss=0.0912]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.95it/s, Epoch=61, Loss=0.09]  \n",
      "100%|██████████| 320/320 [00:02<00:00, 149.82it/s, Epoch=62, Loss=0.0895]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.35it/s, Epoch=63, Loss=0.0887]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.84it/s, Epoch=64, Loss=0.0871]\n",
      "100%|██████████| 320/320 [00:02<00:00, 142.92it/s, Epoch=65, Loss=0.0878]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.76it/s, Epoch=66, Loss=0.0878]\n",
      "100%|██████████| 320/320 [00:01<00:00, 164.39it/s, Epoch=67, Loss=0.0866]\n",
      "100%|██████████| 320/320 [00:02<00:00, 155.51it/s, Epoch=68, Loss=0.0872]\n",
      "100%|██████████| 320/320 [00:02<00:00, 158.04it/s, Epoch=69, Loss=0.0869]\n",
      "100%|██████████| 320/320 [00:02<00:00, 149.71it/s, Epoch=70, Loss=0.0865]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.47it/s, Epoch=71, Loss=0.0847]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.73it/s, Epoch=72, Loss=0.0836]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.22it/s, Epoch=73, Loss=0.0846]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.64it/s, Epoch=74, Loss=0.0826]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.69it/s, Epoch=75, Loss=0.0816]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.39it/s, Epoch=76, Loss=0.0816]\n",
      "100%|██████████| 320/320 [00:02<00:00, 144.73it/s, Epoch=77, Loss=0.0803]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.90it/s, Epoch=78, Loss=0.0798]\n",
      "100%|██████████| 320/320 [00:01<00:00, 160.19it/s, Epoch=79, Loss=0.0794]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.19it/s, Epoch=80, Loss=0.0798]\n",
      "100%|██████████| 320/320 [00:02<00:00, 155.48it/s, Epoch=81, Loss=0.0782]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.30it/s, Epoch=82, Loss=0.0782]\n",
      "100%|██████████| 320/320 [00:02<00:00, 154.78it/s, Epoch=83, Loss=0.0771]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.51it/s, Epoch=84, Loss=0.0767]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.77it/s, Epoch=85, Loss=0.0763]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.92it/s, Epoch=86, Loss=0.0757]\n",
      "100%|██████████| 320/320 [00:02<00:00, 154.46it/s, Epoch=87, Loss=0.077] \n",
      "100%|██████████| 320/320 [00:01<00:00, 163.41it/s, Epoch=88, Loss=0.0742]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.06it/s, Epoch=89, Loss=0.0745]\n",
      "100%|██████████| 320/320 [00:02<00:00, 149.50it/s, Epoch=90, Loss=0.0735]\n",
      "100%|██████████| 320/320 [00:02<00:00, 142.96it/s, Epoch=91, Loss=0.0751]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.35it/s, Epoch=92, Loss=0.0739]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.41it/s, Epoch=93, Loss=0.0728]\n",
      "100%|██████████| 320/320 [00:02<00:00, 159.05it/s, Epoch=94, Loss=0.0734]\n",
      "100%|██████████| 320/320 [00:02<00:00, 155.76it/s, Epoch=95, Loss=0.0709]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.45it/s, Epoch=96, Loss=0.0731]\n",
      "100%|██████████| 320/320 [00:01<00:00, 160.93it/s, Epoch=97, Loss=0.0722]\n",
      "100%|██████████| 320/320 [00:01<00:00, 160.60it/s, Epoch=98, Loss=0.0722]\n",
      "100%|██████████| 320/320 [00:01<00:00, 161.36it/s, Epoch=99, Loss=0.0718]\n",
      "100%|██████████| 320/320 [00:02<00:00, 142.74it/s, Epoch=0, Loss=0.47] \n",
      "100%|██████████| 320/320 [00:01<00:00, 163.77it/s, Epoch=1, Loss=0.328]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.94it/s, Epoch=2, Loss=0.293]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.38it/s, Epoch=3, Loss=0.267]\n",
      "100%|██████████| 320/320 [00:02<00:00, 157.20it/s, Epoch=4, Loss=0.253]\n",
      "100%|██████████| 320/320 [00:02<00:00, 149.94it/s, Epoch=5, Loss=0.243]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.07it/s, Epoch=6, Loss=0.232]\n",
      "100%|██████████| 320/320 [00:01<00:00, 164.10it/s, Epoch=7, Loss=0.221]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.12it/s, Epoch=8, Loss=0.218]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.70it/s, Epoch=9, Loss=0.208]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.06it/s, Epoch=10, Loss=0.206]\n",
      "100%|██████████| 320/320 [00:01<00:00, 161.27it/s, Epoch=11, Loss=0.2]  \n",
      "100%|██████████| 320/320 [00:02<00:00, 140.78it/s, Epoch=12, Loss=0.195]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.13it/s, Epoch=13, Loss=0.191]\n",
      "100%|██████████| 320/320 [00:02<00:00, 138.82it/s, Epoch=14, Loss=0.19] \n",
      "100%|██████████| 320/320 [00:01<00:00, 161.57it/s, Epoch=15, Loss=0.186]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.28it/s, Epoch=16, Loss=0.178]\n",
      "100%|██████████| 320/320 [00:02<00:00, 157.33it/s, Epoch=17, Loss=0.177]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.33it/s, Epoch=18, Loss=0.176]\n",
      "100%|██████████| 320/320 [00:02<00:00, 155.36it/s, Epoch=19, Loss=0.172]\n",
      "100%|██████████| 320/320 [00:02<00:00, 145.36it/s, Epoch=20, Loss=0.17] \n",
      "100%|██████████| 320/320 [00:02<00:00, 145.30it/s, Epoch=21, Loss=0.17] \n",
      "100%|██████████| 320/320 [00:02<00:00, 156.57it/s, Epoch=22, Loss=0.165]\n",
      "100%|██████████| 320/320 [00:02<00:00, 158.53it/s, Epoch=23, Loss=0.162]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.50it/s, Epoch=24, Loss=0.16] \n",
      "100%|██████████| 320/320 [00:02<00:00, 146.68it/s, Epoch=25, Loss=0.158]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.71it/s, Epoch=26, Loss=0.156]\n",
      "100%|██████████| 320/320 [00:02<00:00, 156.95it/s, Epoch=27, Loss=0.156]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.81it/s, Epoch=28, Loss=0.152]\n",
      "100%|██████████| 320/320 [00:02<00:00, 157.16it/s, Epoch=29, Loss=0.15] \n",
      "100%|██████████| 320/320 [00:02<00:00, 147.12it/s, Epoch=30, Loss=0.148]\n",
      "100%|██████████| 320/320 [00:02<00:00, 157.97it/s, Epoch=31, Loss=0.147]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.20it/s, Epoch=32, Loss=0.144]\n",
      "100%|██████████| 320/320 [00:02<00:00, 155.44it/s, Epoch=33, Loss=0.144]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.40it/s, Epoch=34, Loss=0.141]\n",
      "100%|██████████| 320/320 [00:02<00:00, 154.91it/s, Epoch=35, Loss=0.141]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.99it/s, Epoch=36, Loss=0.138]\n",
      "100%|██████████| 320/320 [00:02<00:00, 158.19it/s, Epoch=37, Loss=0.138]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.06it/s, Epoch=38, Loss=0.138]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.09it/s, Epoch=39, Loss=0.133]\n",
      "100%|██████████| 320/320 [00:02<00:00, 144.78it/s, Epoch=40, Loss=0.134]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.59it/s, Epoch=41, Loss=0.132]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.80it/s, Epoch=42, Loss=0.132]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.73it/s, Epoch=43, Loss=0.129]\n",
      "100%|██████████| 320/320 [00:02<00:00, 157.51it/s, Epoch=44, Loss=0.126]\n",
      "100%|██████████| 320/320 [00:02<00:00, 144.42it/s, Epoch=45, Loss=0.128]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.56it/s, Epoch=46, Loss=0.125]\n",
      "100%|██████████| 320/320 [00:02<00:00, 142.77it/s, Epoch=47, Loss=0.125]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.33it/s, Epoch=48, Loss=0.123]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.52it/s, Epoch=49, Loss=0.121]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.63it/s, Epoch=50, Loss=0.121]\n",
      "100%|██████████| 320/320 [00:02<00:00, 154.37it/s, Epoch=51, Loss=0.119]\n",
      "100%|██████████| 320/320 [00:02<00:00, 154.49it/s, Epoch=52, Loss=0.119]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.17it/s, Epoch=53, Loss=0.116]\n",
      "100%|██████████| 320/320 [00:01<00:00, 163.10it/s, Epoch=54, Loss=0.115]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.53it/s, Epoch=55, Loss=0.114]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.14it/s, Epoch=56, Loss=0.113]\n",
      "100%|██████████| 320/320 [00:02<00:00, 144.46it/s, Epoch=57, Loss=0.114]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.18it/s, Epoch=58, Loss=0.113]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.06it/s, Epoch=59, Loss=0.113]\n",
      "100%|██████████| 320/320 [00:02<00:00, 157.44it/s, Epoch=60, Loss=0.11] \n",
      "100%|██████████| 320/320 [00:02<00:00, 138.41it/s, Epoch=61, Loss=0.112]\n",
      "100%|██████████| 320/320 [00:02<00:00, 158.10it/s, Epoch=62, Loss=0.111]\n",
      "100%|██████████| 320/320 [00:02<00:00, 156.39it/s, Epoch=63, Loss=0.107] \n",
      "100%|██████████| 320/320 [00:02<00:00, 143.19it/s, Epoch=64, Loss=0.106]\n",
      "100%|██████████| 320/320 [00:02<00:00, 157.34it/s, Epoch=65, Loss=0.106]\n",
      "100%|██████████| 320/320 [00:02<00:00, 156.85it/s, Epoch=66, Loss=0.106]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.74it/s, Epoch=67, Loss=0.105] \n",
      "100%|██████████| 320/320 [00:02<00:00, 136.74it/s, Epoch=68, Loss=0.103] \n",
      "100%|██████████| 320/320 [00:02<00:00, 152.47it/s, Epoch=69, Loss=0.103]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.27it/s, Epoch=70, Loss=0.102] \n",
      "100%|██████████| 320/320 [00:01<00:00, 162.35it/s, Epoch=71, Loss=0.101] \n",
      "100%|██████████| 320/320 [00:02<00:00, 151.35it/s, Epoch=72, Loss=0.0999]\n",
      "100%|██████████| 320/320 [00:02<00:00, 145.08it/s, Epoch=73, Loss=0.1]   \n",
      "100%|██████████| 320/320 [00:02<00:00, 151.98it/s, Epoch=74, Loss=0.0996]\n",
      "100%|██████████| 320/320 [00:02<00:00, 156.87it/s, Epoch=75, Loss=0.0991]\n",
      "100%|██████████| 320/320 [00:02<00:00, 149.29it/s, Epoch=76, Loss=0.0981]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.40it/s, Epoch=77, Loss=0.0979]\n",
      "100%|██████████| 320/320 [00:02<00:00, 157.61it/s, Epoch=78, Loss=0.0977]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.89it/s, Epoch=79, Loss=0.0971]\n",
      "100%|██████████| 320/320 [00:02<00:00, 144.50it/s, Epoch=80, Loss=0.0956]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.29it/s, Epoch=81, Loss=0.0951]\n",
      "100%|██████████| 320/320 [00:02<00:00, 155.27it/s, Epoch=82, Loss=0.0946]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.88it/s, Epoch=83, Loss=0.0952]\n",
      "100%|██████████| 320/320 [00:02<00:00, 157.88it/s, Epoch=84, Loss=0.0922]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.45it/s, Epoch=85, Loss=0.092] \n",
      "100%|██████████| 320/320 [00:02<00:00, 154.04it/s, Epoch=86, Loss=0.0934]\n",
      "100%|██████████| 320/320 [00:02<00:00, 142.87it/s, Epoch=87, Loss=0.0898]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.01it/s, Epoch=88, Loss=0.0923]\n",
      "100%|██████████| 320/320 [00:02<00:00, 157.18it/s, Epoch=89, Loss=0.0915]\n",
      "100%|██████████| 320/320 [00:01<00:00, 162.25it/s, Epoch=90, Loss=0.0907]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.88it/s, Epoch=91, Loss=0.0901]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.49it/s, Epoch=92, Loss=0.0882]\n",
      "100%|██████████| 320/320 [00:02<00:00, 139.67it/s, Epoch=93, Loss=0.0885]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.79it/s, Epoch=94, Loss=0.0876]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.68it/s, Epoch=95, Loss=0.0895]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.02it/s, Epoch=96, Loss=0.088] \n",
      "100%|██████████| 320/320 [00:02<00:00, 150.43it/s, Epoch=97, Loss=0.0872]\n",
      "100%|██████████| 320/320 [00:02<00:00, 154.07it/s, Epoch=98, Loss=0.0864]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.73it/s, Epoch=99, Loss=0.0852]\n",
      "100%|██████████| 320/320 [00:02<00:00, 155.23it/s, Epoch=0, Loss=0.542]\n",
      "100%|██████████| 320/320 [00:02<00:00, 159.00it/s, Epoch=1, Loss=0.364]\n",
      "100%|██████████| 320/320 [00:01<00:00, 168.07it/s, Epoch=2, Loss=0.314]\n",
      "100%|██████████| 320/320 [00:02<00:00, 155.65it/s, Epoch=3, Loss=0.291]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.59it/s, Epoch=4, Loss=0.278]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.81it/s, Epoch=5, Loss=0.266]\n",
      "100%|██████████| 320/320 [00:02<00:00, 143.57it/s, Epoch=6, Loss=0.252]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.51it/s, Epoch=7, Loss=0.245]\n",
      "100%|██████████| 320/320 [00:02<00:00, 156.73it/s, Epoch=8, Loss=0.238]\n",
      "100%|██████████| 320/320 [00:02<00:00, 144.24it/s, Epoch=9, Loss=0.231]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.22it/s, Epoch=10, Loss=0.229]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.85it/s, Epoch=11, Loss=0.222]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.86it/s, Epoch=12, Loss=0.216]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.52it/s, Epoch=13, Loss=0.214]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.91it/s, Epoch=14, Loss=0.212]\n",
      "100%|██████████| 320/320 [00:02<00:00, 149.38it/s, Epoch=15, Loss=0.206]\n",
      "100%|██████████| 320/320 [00:02<00:00, 144.42it/s, Epoch=16, Loss=0.202]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.66it/s, Epoch=17, Loss=0.202]\n",
      "100%|██████████| 320/320 [00:02<00:00, 154.64it/s, Epoch=18, Loss=0.198]\n",
      "100%|██████████| 320/320 [00:02<00:00, 156.38it/s, Epoch=19, Loss=0.194]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.02it/s, Epoch=20, Loss=0.192]\n",
      "100%|██████████| 320/320 [00:02<00:00, 154.25it/s, Epoch=21, Loss=0.187]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.05it/s, Epoch=22, Loss=0.187]\n",
      "100%|██████████| 320/320 [00:02<00:00, 155.21it/s, Epoch=23, Loss=0.185]\n",
      "100%|██████████| 320/320 [00:02<00:00, 155.91it/s, Epoch=24, Loss=0.181]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.62it/s, Epoch=25, Loss=0.181]\n",
      "100%|██████████| 320/320 [00:02<00:00, 140.38it/s, Epoch=26, Loss=0.179]\n",
      "100%|██████████| 320/320 [00:02<00:00, 157.02it/s, Epoch=27, Loss=0.176]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.41it/s, Epoch=28, Loss=0.173]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.37it/s, Epoch=29, Loss=0.172]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.10it/s, Epoch=30, Loss=0.172]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.87it/s, Epoch=31, Loss=0.17] \n",
      "100%|██████████| 320/320 [00:01<00:00, 163.66it/s, Epoch=32, Loss=0.168]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.52it/s, Epoch=33, Loss=0.168]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.82it/s, Epoch=34, Loss=0.162]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.37it/s, Epoch=35, Loss=0.16] \n",
      "100%|██████████| 320/320 [00:02<00:00, 158.80it/s, Epoch=36, Loss=0.16] \n",
      "100%|██████████| 320/320 [00:02<00:00, 144.55it/s, Epoch=37, Loss=0.158]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.69it/s, Epoch=38, Loss=0.157]\n",
      "100%|██████████| 320/320 [00:01<00:00, 160.91it/s, Epoch=39, Loss=0.157]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.87it/s, Epoch=40, Loss=0.154]\n",
      "100%|██████████| 320/320 [00:01<00:00, 160.40it/s, Epoch=41, Loss=0.153]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.83it/s, Epoch=42, Loss=0.15] \n",
      "100%|██████████| 320/320 [00:02<00:00, 157.06it/s, Epoch=43, Loss=0.151]\n",
      "100%|██████████| 320/320 [00:01<00:00, 168.01it/s, Epoch=44, Loss=0.149]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.73it/s, Epoch=45, Loss=0.148]\n",
      "100%|██████████| 320/320 [00:02<00:00, 159.92it/s, Epoch=46, Loss=0.146]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.15it/s, Epoch=47, Loss=0.144]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.39it/s, Epoch=48, Loss=0.144]\n",
      "100%|██████████| 320/320 [00:02<00:00, 155.42it/s, Epoch=49, Loss=0.143]\n",
      "100%|██████████| 320/320 [00:02<00:00, 149.81it/s, Epoch=50, Loss=0.14] \n",
      "100%|██████████| 320/320 [00:02<00:00, 149.53it/s, Epoch=51, Loss=0.139]\n",
      "100%|██████████| 320/320 [00:02<00:00, 158.12it/s, Epoch=52, Loss=0.14] \n",
      "100%|██████████| 320/320 [00:02<00:00, 155.71it/s, Epoch=53, Loss=0.136]\n",
      "100%|██████████| 320/320 [00:02<00:00, 139.45it/s, Epoch=54, Loss=0.138]\n",
      "100%|██████████| 320/320 [00:01<00:00, 167.39it/s, Epoch=55, Loss=0.137]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.06it/s, Epoch=56, Loss=0.135]\n",
      "100%|██████████| 320/320 [00:01<00:00, 161.84it/s, Epoch=57, Loss=0.133]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.90it/s, Epoch=58, Loss=0.132]\n",
      "100%|██████████| 320/320 [00:02<00:00, 144.94it/s, Epoch=59, Loss=0.129]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.52it/s, Epoch=60, Loss=0.129]\n",
      "100%|██████████| 320/320 [00:02<00:00, 150.21it/s, Epoch=61, Loss=0.129]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.28it/s, Epoch=62, Loss=0.127]\n",
      "100%|██████████| 320/320 [00:02<00:00, 156.32it/s, Epoch=63, Loss=0.128]\n",
      "100%|██████████| 320/320 [00:02<00:00, 147.14it/s, Epoch=64, Loss=0.127]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.42it/s, Epoch=65, Loss=0.126]\n",
      "100%|██████████| 320/320 [00:02<00:00, 149.30it/s, Epoch=66, Loss=0.127]\n",
      "100%|██████████| 320/320 [00:01<00:00, 161.02it/s, Epoch=67, Loss=0.123]\n",
      "100%|██████████| 320/320 [00:02<00:00, 153.14it/s, Epoch=68, Loss=0.123]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.54it/s, Epoch=69, Loss=0.123]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.17it/s, Epoch=70, Loss=0.122]\n",
      "100%|██████████| 320/320 [00:01<00:00, 166.56it/s, Epoch=71, Loss=0.12] \n",
      "100%|██████████| 320/320 [00:02<00:00, 154.22it/s, Epoch=72, Loss=0.119]\n",
      "100%|██████████| 320/320 [00:02<00:00, 159.41it/s, Epoch=73, Loss=0.119]\n",
      "100%|██████████| 320/320 [00:01<00:00, 160.95it/s, Epoch=74, Loss=0.117]\n",
      "100%|██████████| 320/320 [00:02<00:00, 152.03it/s, Epoch=75, Loss=0.118]\n",
      "100%|██████████| 320/320 [00:02<00:00, 143.91it/s, Epoch=76, Loss=0.117]\n",
      "100%|██████████| 320/320 [00:02<00:00, 158.30it/s, Epoch=77, Loss=0.117]\n",
      "100%|██████████| 320/320 [00:02<00:00, 148.96it/s, Epoch=78, Loss=0.116]\n",
      "100%|██████████| 320/320 [00:02<00:00, 140.88it/s, Epoch=79, Loss=0.115]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.23it/s, Epoch=80, Loss=0.114]\n",
      "100%|██████████| 320/320 [00:02<00:00, 137.44it/s, Epoch=81, Loss=0.115]\n",
      "100%|██████████| 320/320 [00:02<00:00, 156.95it/s, Epoch=82, Loss=0.111]\n",
      "100%|██████████| 320/320 [00:02<00:00, 145.63it/s, Epoch=83, Loss=0.111]\n",
      "100%|██████████| 320/320 [00:02<00:00, 157.31it/s, Epoch=84, Loss=0.11] \n",
      "100%|██████████| 320/320 [00:02<00:00, 157.96it/s, Epoch=85, Loss=0.11] \n",
      "100%|██████████| 320/320 [00:01<00:00, 204.07it/s, Epoch=86, Loss=0.11] \n",
      "100%|██████████| 320/320 [00:01<00:00, 160.60it/s, Epoch=87, Loss=0.11] \n",
      "100%|██████████| 320/320 [00:02<00:00, 156.16it/s, Epoch=88, Loss=0.108]\n",
      "100%|██████████| 320/320 [00:02<00:00, 146.27it/s, Epoch=89, Loss=0.108]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.07it/s, Epoch=90, Loss=0.108]\n",
      "100%|██████████| 320/320 [00:01<00:00, 164.27it/s, Epoch=91, Loss=0.106]\n",
      "100%|██████████| 320/320 [00:02<00:00, 156.14it/s, Epoch=92, Loss=0.107]\n",
      "100%|██████████| 320/320 [00:02<00:00, 144.92it/s, Epoch=93, Loss=0.106]\n",
      "100%|██████████| 320/320 [00:01<00:00, 160.14it/s, Epoch=94, Loss=0.104]\n",
      "100%|██████████| 320/320 [00:01<00:00, 163.35it/s, Epoch=95, Loss=0.106]\n",
      "100%|██████████| 320/320 [00:01<00:00, 172.90it/s, Epoch=96, Loss=0.105]\n",
      "100%|██████████| 320/320 [00:01<00:00, 178.29it/s, Epoch=97, Loss=0.104]\n",
      "100%|██████████| 320/320 [00:01<00:00, 168.98it/s, Epoch=98, Loss=0.103]\n",
      "100%|██████████| 320/320 [00:02<00:00, 151.89it/s, Epoch=99, Loss=0.102]\n"
     ]
    }
   ],
   "source": [
    "clf20_100 = MLPClassifier(1152, 4).to(device)\n",
    "train_model(clf20_100, data_20samples, 100, 100)\n",
    "\n",
    "clf20_300 = MLPClassifier(1152, 4).to(device)\n",
    "train_model(clf20_300, data_20samples, 300, 100)\n",
    "\n",
    "clf20_500 = MLPClassifier(1152, 4).to(device)\n",
    "train_model(clf20_500, data_20samples, 500, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84db85f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset('../../datasets', dataset_name='shapenetpart',\n",
    "                      class_choice='airplane', split='val', segmentation=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc785a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.23s/it]\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.21s/it]\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "timesteps = [100, 300, 500]\n",
    "agg_features = {100: [], 300: [], 500: []}\n",
    "all_labels = []\n",
    "\n",
    "for batch in val_loader:\n",
    "    \n",
    "    x = batch[0].transpose(2, 1).to(device)\n",
    "    labels = batch[2]\n",
    "    features, coords = model.get_features(x, timesteps)\n",
    "    for t in timesteps:\n",
    "        f = combine_features(x, features[t], coords[t])\n",
    "        agg_features[t].append(f.transpose(2, 1).flatten(start_dim=0, end_dim=1))\n",
    "        \n",
    "    all_labels.append(labels.flatten(start_dim=0, end_dim=1))\n",
    "\n",
    "for t in timesteps:\n",
    "    agg_features[t] = torch.cat(agg_features[t], dim=0)\n",
    "    \n",
    "val_data = {\n",
    "    'features': agg_features,\n",
    "    'labels': torch.cat(all_labels).to(device)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80fbddbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "384it [00:00, 737.20it/s]\n",
      "384it [00:00, 700.58it/s]\n",
      "384it [00:00, 712.85it/s]\n",
      "384it [00:00, 642.43it/s]\n",
      "384it [00:00, 701.38it/s]\n",
      "384it [00:00, 693.99it/s]\n",
      "384it [00:00, 718.98it/s]\n",
      "384it [00:00, 677.20it/s]\n",
      "384it [00:00, 767.36it/s]\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    3: [clf3_100, clf3_300, clf3_500],\n",
    "    10: [clf10_100, clf10_300, clf10_500],\n",
    "    20: [clf20_100, clf20_300, clf20_500]\n",
    "}\n",
    "timesteps = [100, 300, 500]\n",
    "\n",
    "table = []\n",
    "predictions = {\n",
    "    3: [],\n",
    "    10: [],\n",
    "    20: []\n",
    "}\n",
    "for num_samples, clfs in models.items():\n",
    "    for clf, t in zip(clfs, timesteps):\n",
    "        mIoU, ious, preds, loss = validate(clf, val_data, t)\n",
    "        table.append({'num_samples': num_samples,\n",
    "                      'timestep': t,\n",
    "                      'mIOU': mIoU.item(),\n",
    "                      'part1': ious[0].item(),\n",
    "                      'part2': ious[1].item(),\n",
    "                      'part3': ious[2].item(),\n",
    "                      'part4': ious[3].item()\n",
    "                     })\n",
    "        predictions[num_samples].append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db503efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.20.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.3.5\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5847f2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_samples</th>\n",
       "      <th>timestep</th>\n",
       "      <th>mIOU</th>\n",
       "      <th>part1</th>\n",
       "      <th>part2</th>\n",
       "      <th>part3</th>\n",
       "      <th>part4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>300</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_samples  timestep   mIOU  part1  part2  part3  part4\n",
       "0            3       100  0.613  0.781  0.686  0.649  0.338\n",
       "1            3       300  0.538  0.721  0.564  0.626  0.241\n",
       "2            3       500  0.477  0.650  0.487  0.569  0.202\n",
       "3           10       100  0.682  0.804  0.724  0.730  0.471\n",
       "4           10       300  0.591  0.748  0.653  0.633  0.331\n",
       "5           10       500  0.561  0.732  0.596  0.590  0.326\n",
       "6           20       100  0.692  0.800  0.726  0.734  0.508\n",
       "7           20       300  0.634  0.765  0.656  0.701  0.413\n",
       "8           20       500  0.605  0.743  0.621  0.687  0.367"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36b1843b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 2048])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[3][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7ff7e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245ddcfcc5584535b6d6aa7377c35f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k3d.points(center(val_dataset[25][0].t().unsqueeze(0))[0], point_size=0.05,\n",
    "           attribute=predictions[20][0][25].cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
